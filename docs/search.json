[{"path":"index.html","id":"regressions-and-causal-inference","chapter":"“Regressions and Causal Inference”","heading":"“Regressions and Causal Inference”","text":" Welcome site course PS9591: “Regressions Causal Inference” Western University, taught Sebastián Vallejo Vera. week, find lecture slides, lecture code, lab exercises, lab code corresponding topic.class divided lectures tutorials. go lectures tutorials simultaneously. Thus, arranged website way shows suggested order lecture tutorials carried .start, don’t forget read Syllabus check Perusall readings course. site corrected/updated throughout semester(s).","code":""},{"path":"index.html","id":"about-tutorials","chapter":"“Regressions and Causal Inference”","heading":"0.1 About Tutorials","text":"tutorials interactive R documents can also run computer. allows practice concepts experiment different approaches pace. ’s get started.","code":""},{"path":"index.html","id":"prerequisites","chapter":"“Regressions and Causal Inference”","heading":"0.1.1 Prerequisites","text":"running tutorials, make sure :R installed computer (version 4.0.0 higher)RStudio installed (recent version)following R packages installed. can install running commands R:","code":"\n# Install required packages\ninstall.packages(\"learnr\")\ninstall.packages(\"wooldridge\")\ninstall.packages(\"tidyverse\")\ninstall.packages(\"tidylog\")\ninstall.packages(sjPlot) # to plot some models\ninstall.packages(readstata13) # to load .dta files"},{"path":"index.html","id":"running-a-tutorial","chapter":"“Regressions and Causal Inference”","heading":"0.1.2 Running a Tutorial","text":"two ways run tutorial locally:","code":""},{"path":"index.html","id":"method-1-using-rstudio","chapter":"“Regressions and Causal Inference”","heading":"0.1.2.1 Method 1: Using RStudio","text":"Download tutorial file (.Rmd extension)Open RStudioClick “Run Document” button top editorThe tutorial open new window","code":""},{"path":"index.html","id":"method-2-using-r-console","chapter":"“Regressions and Causal Inference”","heading":"0.1.2.2 Method 2: Using R Console","text":"tutorial file working directory, can run:Replace “filename” name tutorial file (without .Rmd extension).","code":"\nrmarkdown::run_tutorial(\"filename\", package = \"learnr\")"},{"path":"index.html","id":"tips-for-success","chapter":"“Regressions and Causal Inference”","heading":"0.1.3 Tips for Success","text":"working tutorials locally:Make sure required packages loaded tutorial’s setup chunkIf modify tutorial code, save file runningTo clear tutorial cache start fresh, just click “Start ” button bottom left corner.","code":""},{"path":"index.html","id":"troubleshooting-common-issues","chapter":"“Regressions and Causal Inference”","heading":"0.1.4 Troubleshooting Common Issues","text":"encounter problems:Tutorial won’t knit: Check required packages installedExercise chunks don’t run: Verify learnr properly loadedPrevious answers persist: Clear cache using code provided abovePackage found: Run install.packages() missing package","code":""},{"path":"index.html","id":"getting-help","chapter":"“Regressions and Causal Inference”","heading":"0.1.5 Getting Help","text":"need assistance:Check tutorial error messages specific package requirementsReview setup chunk missing dependenciesConsult learnr documentationAsk questions office hours send e-mailAsk ChatGPT (?)","code":""},{"path":"index.html","id":"next-steps","chapter":"“Regressions and Causal Inference”","heading":"0.1.6 Next Steps","text":"getting tutorials running locally, can:Experiment modifying codeCreate practice exercisesTry different approaches analysis tasksSave work future referenceRemember tutorials learning tools. Feel free experiment try different approaches – ’s learn best!","code":""},{"path":"index.html","id":"assignments","chapter":"“Regressions and Causal Inference”","heading":"0.2 Assignments","text":"list assignments course. assignments must handed pdf documents using R Markdown.","code":""},{"path":"index.html","id":"final-exam","chapter":"“Regressions and Causal Inference”","heading":"0.3 Final Exam","text":"final exam require students replicate findings papers, interpret results. Final Exam, post required datasets replication exercise :COMING SOON…","code":""},{"path":"index.html","id":"acknowledgments","chapter":"“Regressions and Causal Inference”","heading":"0.4 Acknowledgments","text":"organization course based great textbook ‘Effect: Introduction Research Design Causality’ Nick Huntington-Klein, freely available . code used throughout main lectures patchwork code, code borrows heavily internet (’s true code). try best give credit original authors code (possible). code labs created revised two amazing doctoral students1 Western University, Hugo Machado John Santos (posted permission).","code":""},{"path":"lecture-1-what-is-causal-inference.html","id":"lecture-1-what-is-causal-inference","chapter":"1 Lecture 1: What is Causal Inference?","heading":"1 Lecture 1: What is Causal Inference?","text":"","code":""},{"path":"lecture-1-what-is-causal-inference.html","id":"slides","chapter":"1 Lecture 1: What is Causal Inference?","heading":"Slides","text":"2 Causal Inference? (link)","code":""},{"path":"lecture-1-what-is-causal-inference.html","id":"introduction","chapter":"1 Lecture 1: What is Causal Inference?","heading":"1.1 Introduction","text":"first week, introduce ‘causal inference’ concept interest, main problems determining causality observational data. fancy code week.lecture slide displayed full :\nFigure 1.1: Slides 2 Causal Inference?.\n","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","text":"tutorial created Hugo Machado John Santos (minor adaptations ).tutorial guide setting R RStudio, installing essential packages, learning basics RMarkdown, suggesting best practices help keep work organized find solutions common problems (definitely encounter).","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"installing-r-and-rstudio","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.1 Installing R and RStudio","text":"R programming language ’ll using course. optimized statistics data analysis. Additionally, open source, easily customizable, popular academia, gives edge proprietary (e.g., Stata, SPSS) general purpose frameworks (e.g., Python) best language learn social scientists working data.Go R Project website: https://mirror.csclub.uwaterloo.ca/CRAN/Go R Project website: https://mirror.csclub.uwaterloo.ca/CRAN/link send CRAN mirror hosted University Waterloo.link send CRAN mirror hosted University Waterloo.Select appropriate link operating system (Windows, macOS, Linux).Select appropriate link operating system (Windows, macOS, Linux).Follow instructions download install R.\nmacOS users:\nMac Apple Silicon chip (M1, M2, M3, etc.), choose arm64 version.\nMac Intel chip, choose x86_64 version.\n\nNote: updating R, ’ll need reinstall packages. ’s good idea time right deadline.\nFollow instructions download install R.macOS users:\nMac Apple Silicon chip (M1, M2, M3, etc.), choose arm64 version.\nMac Intel chip, choose x86_64 version.\nmacOS users:Mac Apple Silicon chip (M1, M2, M3, etc.), choose arm64 version.Mac Intel chip, choose x86_64 version.Note: updating R, ’ll need reinstall packages. ’s good idea time right deadline.Note: updating R, ’ll need reinstall packages. ’s good idea time right deadline.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"rstudio","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.1.1 RStudio","text":"RStudio Integrated Development Environment (IDE) makes working R much easier user-friendly.Go RStudio Desktop download page: https://posit.co/download/rstudio-desktop/Download free version RStudio Desktop operating system.Follow instructions install RStudio.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"a-quick-tour-of-the-rstudio-interface","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.2 A Quick Tour of the RStudio Interface","text":"open RStudio, ’ll see four main panes:Source (top-left): write edit R code RMarkdown documents.Console (bottom-left): can run R code interactively see output.Environment/History (top-right): Environment tab shows objects (data, variables, functions) created. History tab shows commands run.Files/Plots/Packages/Help (bottom-right): pane several tabs:\nFiles: Allows browse manage files computer.\nPlots: Displays plots create.\nPackages: Shows installed R packages allows load/unload .\nHelp: Displays R documentation.\nFiles: Allows browse manage files computer.Plots: Displays plots create.Packages: Shows installed R packages allows load/unload .Help: Displays R documentation.can customize layout panes Tools > Global Options > Pane Layout.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"r-working-directory","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.3 R Working Directory","text":"working directory folder R look files save output default. Issues conflicting working directories common, especially multiple folders different projects. best practices deal .Using setwd(): can use setwd() function set working directory. example, setwd(\"~/Documents/R Projects/MyProject\") sets working directory “MyProject” folder within “R Projects” folder “Documents” directory. can also open new script (tab top left), right-click tab, tell R “Set working directory” wherever script located. working external data files (e.g., .dta database, example), data need folder script working .Using RStudio Interface: can also set working directory RStudio menu: “Session” > “Set Working Directory” > “Choose Directory…”.R Projects: better organization, consider creating R Projects assignments. R Project special type working directory makes easier manage code, data, output. can create new project going “File” > “New Project…”. RStudio automatically set working directory project folder. information working projects, consult guide: https://support.posit.co/hc/en-us/articles/200526207-Using-RStudio-Projects","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"introduction-to-rmarkdown","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.4 Introduction to RMarkdown","text":"RMarkdown file format allows combine R code, output (e.g., tables, plots), text single document. ’s powerful tool creating reproducible reports assignments. can also use write HTML render PDFs. However, can little finicky intuitive write , compared common word processors like MSWord Google Docs, takes practice (patience) get place feel comfortable writing .","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"why-use-rmarkdown","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.4.1 Why Use RMarkdown?","text":"Reproducibility: code, output, text one place, making easy reproduce analysis.Clarity: can interweave code explanations narrative, making work easier understand.Efficiency: can generate different output formats (HTML, PDF, Word) RMarkdown file. outputs also look pretty nice.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"basic-rmarkdown-syntax","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.4.2 Basic RMarkdown Syntax","text":"Code Chunks: R code enclosed “chunks” start ```{r} end ```.\n\n# R code chunk\nx <- 10\ny <- 20\nx + yCode Chunks: R code enclosed “chunks” start ```{r} end ```.Headers: can create headers using #, ##, ###, etc. number # determines level header.Headers: can create headers using #, ##, ###, etc. number # determines level header.Text Formatting: can format text using Markdown syntax. example:\nItalic: *italic*\nBold: **bold**\nCode: `code`\nLinks: [Link Text](URL)\nText Formatting: can format text using Markdown syntax. example:Italic: *italic*Bold: **bold**Code: `code`Links: [Link Text](URL)","code":"\n# This is an R code chunk\nx <- 10\ny <- 20\nx + y"},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"creating-an-rmarkdown-file","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.4.3 Creating an RMarkdown File","text":"RStudio, go “File” > “New File” > “R Markdown…”.Choose title author name.Select desired output format (e.g., HTML, PDF).Click “OK”.RStudio create new RMarkdown file example content. can edit file, add code text, “knit” generate output document.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"knitting","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.4.4 Knitting","text":"“Knitting” process converting RMarkdown file output document. knit document, click “Knit” button top Source pane. can choose output format dropdown menu next “Knit” button.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"rmarkdown-cheatsheet","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.4.5 RMarkdown cheatsheet:","text":"useful quick guide can use help formatting related tasks: https://rstudio.github.io/cheatsheets/html/rmarkdown.html","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"installing-r-packages","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.5 Installing R Packages","text":"R packages extend functionality base R. progress course, ’ll use several packages help perform different tasks related statistical analysis. need install packages , need load new session.basic packages use go installing .Experienced: experience R, might interested exploring pacman package. provides convenient way manage packages, allowing load, install, update packages using single function, p_load(). example, instead repeated install.packages operations , pacman installed use one line like: pacman::p_load(devtools, remotes, foreign, readstata13, rio, labelled, sjlabelled, tidyverse, fixest, wooldridge, modelsummary, stargazer, ggplot2, knitr, kableExtra, markdown, car, carData, lmtest, sandwich, survey, srvyr). Using pacman may also automatically install packages CRAN, Bioconductor GitHub, according latest version . ’re interested, can learn pacman CRAN page. However, course, using standard install.packages() method sufficient.","code":"\n# Install packages for data import/export:\ninstall.packages(\"foreign\")\ninstall.packages(\"rio\")\n\n# Install tidyverse, a collection of packages for data science:\ninstall.packages(\"tidyverse\")\n\n# Install wooldridge, which contains datasets you will use for the assignments:\ninstall.packages(\"wooldridge\")\n\n# Install knitr and markdown for improved RMarkdown functionality:\ninstall.packages(\"knitr\")\ninstall.packages(\"markdown\")"},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"using-ai-tools-to-assist-with-r-programming","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.6 Using AI Tools to Assist with R Programming","text":"Large Language Models (LLMs) related AI tools, ChatGPT, Copilot Gemini, can valuable assistants learning using R. used correctly, can save lot time, especially debugging finding ways performing specific tasks ’re really familiar . However, ’s crucial use responsibly ethically. general tips using tools.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"how-ai-can-help","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.6.1 How AI Can Help","text":"Code Suggestions Auto-Completion: AI tools like GitHub Copilot can suggest code snippets type, helping write code faster fewer errors. also hallucinate times, mindful suggesting. ’m big fan auto-complete, ’s usually better either ask something specific ask edits base code ’ve already written.Debugging Assistance: encounter error, AI can help explain error message means suggest potential solutions. Just copy paste error message (relevant excerpt), tell wanted , ask causing error.Understanding Functions Packages: AI can provide explanations R functions work, arguments take, use effectively. Check documentation make sure LLMs telling something mark.Learning New Concepts: can ask AI explain statistical concepts R programming topics way ’s easy understand. Documentation references StackOverflow can bit cryptic.Finding Relevant Documentation: AI can help locate relevant documentation R packages functions.Generating Code Specific Tasks: can describe task want accomplish, AI can generate R code perform task. better informed prompt , better output get. models typically better contained, well-defined, tasks broad tasks underspecified.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"limitations-and-ethical-considerations","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.6.2 Limitations and Ethical Considerations","text":"Critical Thinking Essential: AI tool, replacement understanding. Always critically evaluate code generated AI. Make sure understand works using .Don’t Blindly Copy Paste: Avoid copying pasting code without understanding . can lead errors lack comprehension.Avoid Plagiarism: transparent use AI. Properly cite AI-generated code ideas assignments. instructors need know work came AI assistance.AI Makes Mistakes: AI perfect. can generate incorrect inefficient code. Always test code thoroughly.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"prompt-engineering-tips","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.6.3 Prompt Engineering Tips","text":"Specific Clear: specific prompts, better AI understand request.Provide Context: ’re asking specific piece code, include relevant code prompt.Break Complex Tasks: complex task, break smaller, manageable steps.Iterate Refine: AI doesn’t give answer ’re looking , try rephrasing prompt providing information.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"example","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.6.4 Example","text":"’s example use AI tool help generate plot:Prompt: “data frame called mydata columns x y. can create scatterplot y x using ggplot2, blue points red trend line?”AI-Generated Code (example):Remember: still need load ggplot2 package (library(ggplot2)) data frame mydata loaded R environment code work.","code":"\nggplot(mydata, aes(x = x, y = y)) +\n  geom_point(color = \"blue\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\")"},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"quick-example-importing-and-checking-data-from-wooldridge","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.7 Quick Example: Importing and Checking Data from wooldridge","text":"Let’s load dataset wooldridge package take quick look . ’ll use wage1 dataset, contains information wages individual characteristics.Explanation:library(wooldridge): Loads wooldridge package, making datasets available.data(\"wage1\"): Loads wage1 dataset R environment.head(wage1): Displays first six rows dataset, allowing see variable names sample data.\nExercise: Try changing number inside parentheses head() function display different number rows.\nExercise: Try changing number inside parentheses head() function display different number rows.summary(wage1): Provides descriptive statistics variable dataset (e.g., mean, median, min, max, quartiles).str(wage1): Shows structure dataset, including data type variable (e.g., numeric, integer, factor).","code":"\n# Load the wooldridge package\nlibrary(wooldridge)\n\n# Load the wage1 dataset\ndata(\"wage1\")\n\n# Display the first few rows of the dataset\nhead(wage1)##   wage educ exper tenure nonwhite female married numdep smsa northcen south west construc ndurman trcommpu trade services profserv profocc clerocc servocc\n## 1 3.10   11     2      0        0      1       0      2    1        0     0    1        0       0        0     0        0        0       0       0       0\n## 2 3.24   12    22      2        0      1       1      3    1        0     0    1        0       0        0     0        1        0       0       0       1\n## 3 3.00   11     2      0        0      0       0      2    0        0     0    1        0       0        0     1        0        0       0       0       0\n## 4 6.00    8    44     28        0      0       1      0    1        0     0    1        0       0        0     0        0        0       0       1       0\n## 5 5.30   12     7      2        0      0       1      1    0        0     0    1        0       0        0     0        0        0       0       0       0\n## 6 8.75   16     9      8        0      0       1      0    1        0     0    1        0       0        0     0        0        1       1       0       0\n##      lwage expersq tenursq\n## 1 1.131402       4       0\n## 2 1.175573     484       4\n## 3 1.098612       4       0\n## 4 1.791759    1936     784\n## 5 1.667707      49       4\n## 6 2.169054      81      64\n# Get a summary of the dataset\nsummary(wage1)##       wage             educ           exper           tenure          nonwhite          female          married           numdep           smsa       \n##  Min.   : 0.530   Min.   : 0.00   Min.   : 1.00   Min.   : 0.000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.000   Min.   :0.0000  \n##  1st Qu.: 3.330   1st Qu.:12.00   1st Qu.: 5.00   1st Qu.: 0.000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:0.0000  \n##  Median : 4.650   Median :12.00   Median :13.50   Median : 2.000   Median :0.0000   Median :0.0000   Median :1.0000   Median :1.000   Median :1.0000  \n##  Mean   : 5.896   Mean   :12.56   Mean   :17.02   Mean   : 5.105   Mean   :0.1027   Mean   :0.4791   Mean   :0.6084   Mean   :1.044   Mean   :0.7224  \n##  3rd Qu.: 6.880   3rd Qu.:14.00   3rd Qu.:26.00   3rd Qu.: 7.000   3rd Qu.:0.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:2.000   3rd Qu.:1.0000  \n##  Max.   :24.980   Max.   :18.00   Max.   :51.00   Max.   :44.000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :6.000   Max.   :1.0000  \n##     northcen         south             west           construc          ndurman          trcommpu           trade           services         profserv     \n##  Min.   :0.000   Min.   :0.0000   Min.   :0.0000   Min.   :0.00000   Min.   :0.0000   Min.   :0.00000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n##  1st Qu.:0.000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n##  Median :0.000   Median :0.0000   Median :0.0000   Median :0.00000   Median :0.0000   Median :0.00000   Median :0.0000   Median :0.0000   Median :0.0000  \n##  Mean   :0.251   Mean   :0.3555   Mean   :0.1692   Mean   :0.04563   Mean   :0.1141   Mean   :0.04373   Mean   :0.2871   Mean   :0.1008   Mean   :0.2586  \n##  3rd Qu.:0.750   3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:0.00000   3rd Qu.:0.0000   3rd Qu.:0.00000   3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:1.0000  \n##  Max.   :1.000   Max.   :1.0000   Max.   :1.0000   Max.   :1.00000   Max.   :1.0000   Max.   :1.00000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n##     profocc          clerocc          servocc           lwage            expersq          tenursq       \n##  Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :-0.6349   Min.   :   1.0   Min.   :   0.00  \n##  1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.: 1.2030   1st Qu.:  25.0   1st Qu.:   0.00  \n##  Median :0.0000   Median :0.0000   Median :0.0000   Median : 1.5369   Median : 182.5   Median :   4.00  \n##  Mean   :0.3669   Mean   :0.1673   Mean   :0.1407   Mean   : 1.6233   Mean   : 473.4   Mean   :  78.15  \n##  3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.: 1.9286   3rd Qu.: 676.0   3rd Qu.:  49.00  \n##  Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   : 3.2181   Max.   :2601.0   Max.   :1936.00\n# Get the structure of the dataset\nstr(wage1)## 'data.frame':    526 obs. of  24 variables:\n##  $ wage    : num  3.1 3.24 3 6 5.3 ...\n##  $ educ    : int  11 12 11 8 12 16 18 12 12 17 ...\n##  $ exper   : int  2 22 2 44 7 9 15 5 26 22 ...\n##  $ tenure  : int  0 2 0 28 2 8 7 3 4 21 ...\n##  $ nonwhite: int  0 0 0 0 0 0 0 0 0 0 ...\n##  $ female  : int  1 1 0 0 0 0 0 1 1 0 ...\n##  $ married : int  0 1 0 1 1 1 0 0 0 1 ...\n##  $ numdep  : int  2 3 2 0 1 0 0 0 2 0 ...\n##  $ smsa    : int  1 1 0 1 0 1 1 1 1 1 ...\n##  $ northcen: int  0 0 0 0 0 0 0 0 0 0 ...\n##  $ south   : int  0 0 0 0 0 0 0 0 0 0 ...\n##  $ west    : int  1 1 1 1 1 1 1 1 1 1 ...\n##  $ construc: int  0 0 0 0 0 0 0 0 0 0 ...\n##  $ ndurman : int  0 0 0 0 0 0 0 0 0 0 ...\n##  $ trcommpu: int  0 0 0 0 0 0 0 0 0 0 ...\n##  $ trade   : int  0 0 1 0 0 0 1 0 1 0 ...\n##  $ services: int  0 1 0 0 0 0 0 0 0 0 ...\n##  $ profserv: int  0 0 0 0 0 1 0 0 0 0 ...\n##  $ profocc : int  0 0 0 0 0 1 1 1 1 1 ...\n##  $ clerocc : int  0 0 0 1 0 0 0 0 0 0 ...\n##  $ servocc : int  0 1 0 0 0 0 0 0 0 0 ...\n##  $ lwage   : num  1.13 1.18 1.1 1.79 1.67 ...\n##  $ expersq : int  4 484 4 1936 49 81 225 25 676 484 ...\n##  $ tenursq : int  0 4 0 784 4 64 49 9 16 441 ...\n##  - attr(*, \"time.stamp\")= chr \"25 Jun 2011 23:03\""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"getting-help-in-r","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.8 Getting Help in R","text":"several ways get help R:? help(): access documentation specific function, type ? followed function name (e.g., ?mean). can also use help(mean).?? help.search(): search help topics related keyword, use ?? followed keyword (e.g., ??regression). can also use help.search(\"regression\").Online Resources: R community active online. Websites like Stack Overflow (https://stackoverflow.com/questions/tagged/r) great places find answers common R questions.Package Vignettes: Many R packages include vignettes, longer, tutorial-style documents demonstrate use package. can access using browseVignettes() function.Package Websites: packages dedicated websites additional resources, tutorials, articles, examples. can typically found searching package name followed “R package” search engine.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"style-guides-in-r","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.9 Style Guides in R","text":"Coding style guides sets conventions prescribe code formatted written. Following style guide can make code readable, maintainable, consistent.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"the-tidyverse-style-guide","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.9.1 The tidyverse Style Guide","text":"tidyverse style guide, developed Hadley Wickham RStudio team, widely used style guide R. covers various aspects coding style, including:File namesObject namesSyntaxSpacingControl flowCommentsYou can find tidyverse style guide : https://style.tidyverse.org/. Note: try follow guide, incredibly good .","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"quick-examples","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.9.2 Quick Examples","text":"examples tidyverse style guidelines:File Names: Use .R extension R script files .Rmd R Markdown files. File names meaningful use lowercase letters, numbers, underscores (e.g., process_data.R, analysis_report.Rmd).Object Names: Use lowercase underscores separate words (e.g., my_variable, data_frame). descriptive concise.Spacing: Place spaces around operators (e.g., x + y, x+y) commas (e.g., mean(x, na.rm = TRUE), mean(x,na.rm=TRUE)).Indentation: Use two spaces indentation. use tabs.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"other-style-guides","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.9.3 Other Style Guides","text":"tidyverse style guide popular, style guides might encounter choose follow, :Google’s R Style Guide: https://google.github.io/styleguide/Rguide.htmlThe Bioconductor Style Guide: https://contributions.bioconductor.org/Ultimately, important thing consistent style, regardless guide choose follow. style guides agree basic principles writing clear readable code.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"protips-for-r-success","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.10 Protips for R Success","text":"","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"enable-helpful-rstudio-options","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.10.1 Enable Helpful RStudio Options","text":"options can make coding experience pleasant efficient:Highlight R function calls: Go “Tools” > “Global Options” > “Code” > “Display” check “Highlight R function calls.” visually distinguish function names code.Rainbow parentheses: “Display” settings, check “Rainbow parentheses.” color-code matching parentheses, making easier track nested functions.Use dark theme: find staring screen long periods, dark theme can help reduce eye strain. Go “Tools” > “Global Options” > “Appearance” choose dark theme “Editor Theme” options.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"good-coding-practices","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.10.2 Good Coding Practices","text":"Organization: Use clear directory structure projects. Keep data, code, output separate folders.Comments: Explain code using comments (lines starting #). Focus explaining behind code, just .Readability: Use consistent spacing indentation make code easy read. RStudio can help automatically indenting code.Section Headings: Use # create section headings organize R scripts. number # determines level heading (e.g., # top-level heading, ## subheading, etc.).Don’t Overwrite: Avoid overwriting original variables. Create new variables need modify data.Backups: Regularly back work. Save reusable code snippets future use. larger projects, consider using separate R scripts different tasks (e.g., data cleaning, analysis, reporting).Coding Language: Learning code like learning new language. takes time practice. patient .Precision: Approach analysis care attention detail. Avoid rushing, especially tired.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"solutions-to-common-problems","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.10.3 Solutions to Common Problems","text":"Knitting Issues:\nRestart RStudio try knitting .\nCheck special characters (e.g., Greek letters) might causing problems.\nMake sure PDF file (’re knitting PDF) open another program.\nDelete temporary .md .tex files created knitting process.\nConsider disabling “use tinytex compiling .tex files” “Tools” > “Global Options” > “Sweave” ’re issues TinyTeX.\nRestart RStudio try knitting .Check special characters (e.g., Greek letters) might causing problems.Make sure PDF file (’re knitting PDF) open another program.Delete temporary .md .tex files created knitting process.Consider disabling “use tinytex compiling .tex files” “Tools” > “Global Options” > “Sweave” ’re issues TinyTeX.Error Messages:\nCarefully check function arguments. enter correctly right order?\nPay attention capitalization use quotes.\nencounter naming conflicts (e.g., dplyr::recode() vs. car::recode()), specify package want use (e.g., dplyr::recode()).\nCarefully check function arguments. enter correctly right order?Pay attention capitalization use quotes.encounter naming conflicts (e.g., dplyr::recode() vs. car::recode()), specify package want use (e.g., dplyr::recode()).Model Problems:\nDouble-check ’re using correct variables model.\nReview recoding steps performed. make mistakes might affecting results?\nDouble-check ’re using correct variables model.Review recoding steps performed. make mistakes might affecting results?","code":""},{"path":"lecture-2-introduction-to-causal-inference.html","id":"lecture-2-introduction-to-causal-inference","chapter":"3 Lecture 2: Introduction to Causal Inference","heading":"3 Lecture 2: Introduction to Causal Inference","text":"","code":""},{"path":"lecture-2-introduction-to-causal-inference.html","id":"slides-1","chapter":"3 Lecture 2: Introduction to Causal Inference","heading":"Slides","text":"3 Introduction Causal Inference (link)","code":""},{"path":"lecture-2-introduction-to-causal-inference.html","id":"introduction-1","chapter":"3 Lecture 2: Introduction to Causal Inference","heading":"3.1 Introduction","text":"now dive deeper causal inference counterfactual problem. show randomized trails solve counterfactual problem, also counterfactual problem still problem using observational data.lecture slide displayed full :\nFigure 3.1: Slides 3 Introduction Causal Inference.\n","code":"\nlibrary(tidyverse) # for wrangling data\nlibrary(tidylog) # to know what we are wrangling"},{"path":"lecture-2-introduction-to-causal-inference.html","id":"vignette-2.1","chapter":"3 Lecture 2: Introduction to Causal Inference","heading":"3.2 Vignette 2.1","text":"Usually, know data generation process, , gods. Let’s create world taking treatment (e.g., taking pill) positively affect Y (e.g., health) one unit. Let’s run experiment.Now can create counterfactual:Let’s look counterfactual:Now let’s give individual treatment (either pill placebo):can see average effect pill treated group (remember lecture effect , essence, difference receive treatment, ):can plot :","code":"\ndf <- data.frame(health_no_pill= rnorm(5000),\n                 # Randomly assign a treatment\n                 pill=sample(c(0,1),5000,replace=T))\nhist(df$health_no_pill)\nknitr::kable(table(df$pill), format=\"markdown\")\ndf <- df %>%\n  mutate(health_w_pill = health_no_pill + 1) # Our Y when A=1 aka our counterfactual## mutate: new variable 'health_w_pill' (double) with 5,000 unique values and 0% NA\nhealth_w_pill <- cbind.data.frame(df$health_w_pill,\"with Pill\")\ncolnames(health_w_pill) <- c(\"health\",\"treatment\")\nhealth_no_pill <- cbind.data.frame(df$health_no_pill,\"without Pill\")\ncolnames(health_no_pill) <- c(\"health\",\"treatment\")\ncomparison_y <- rbind.data.frame(health_w_pill,health_no_pill)\n\ncomparison_y %>%\n  group_by(treatment) %>%\n  mutate(mean_health = mean(health)) %>%\n  ungroup() %>%\n  ggplot(aes(x=health,fill = treatment,color = treatment)) +\n  geom_density(alpha = .5) +\n  scale_x_continuous(breaks = scales::pretty_breaks(n = 8)) +\n  geom_vline(aes(xintercept = mean_health, color = treatment ),\n             linetype = \"dashed\")## group_by: one grouping variable (treatment)\n## mutate (grouped): new variable 'mean_health' (double) with 2 unique values and 0% NA\n## ungroup: no grouping variables remain\ndf <- df %>%\n  mutate(health_obs = ifelse(pill==1,health_w_pill,health_no_pill))## mutate: new variable 'health_obs' (double) with 5,000 unique values and 0% NA\nhead(df,10)##    health_no_pill pill health_w_pill  health_obs\n## 1     -1.34434243    1    -0.3443424 -0.34434243\n## 2     -0.07438050    1     0.9256195  0.92561950\n## 3     -0.86701976    0     0.1329802 -0.86701976\n## 4      0.40299425    1     1.4029942  1.40299425\n## 5     -1.55206720    1    -0.5520672 -0.55206720\n## 6      0.63819199    1     1.6381920  1.63819199\n## 7     -1.41243355    1    -0.4124336 -0.41243355\n## 8      0.20591766    1     1.2059177  1.20591766\n## 9      0.86313538    0     1.8631354  0.86313538\n## 10    -0.01354962    0     0.9864504 -0.01354962\ndf %>%\n  group_by(pill) %>%\n  summarize(health = mean(health_obs))## group_by: one grouping variable (pill)\n## summarize: now 2 rows and 2 columns, ungrouped## # A tibble: 2 × 2\n##    pill  health\n##   <dbl>   <dbl>\n## 1     0 -0.0207\n## 2     1  0.978\ndf %>%\n  group_by(pill) %>%\n  mutate(mean_health_obs = mean(health_obs)) %>%\n  ungroup() %>%\n  ggplot(aes(x=health_obs,fill = factor(pill),color = factor(pill))) +\n  geom_density(alpha = .5) +\n  scale_x_continuous(breaks = scales::pretty_breaks(n = 8)) +\n  geom_vline(aes(xintercept = mean_health_obs, color = factor(pill) ),\n             linetype = \"dashed\")## group_by: one grouping variable (pill)\n## mutate (grouped): new variable 'mean_health_obs' (double) with 2 unique values and 0% NA\n## ungroup: no grouping variables remain"},{"path":"lecture-2-introduction-to-causal-inference.html","id":"vignette-2.2","chapter":"3 Lecture 2: Introduction to Causal Inference","heading":"3.3 Vignette 2.2","text":"Ok… happens randomize? observational data, …Let’s see happens now estimated mean average ‘effect’ (remember lecture effect , essence, difference receive treatment, ):Oh ! actual effect pill, know 1 since created . However, properly model (RDD!), (remember lecture effect , essence, difference receive treatment, ):","code":"\ndf <- data.frame(income = runif(10000)) %>%\n  # In this case, your health is determined randomly AND by your levels of income\n  mutate(health_no_pill = rnorm(10000) + income,\n         health_w_pill = health_no_pill + 1) %>%\n  # Now we give the pill only to people that have money\n  mutate(pill = income > .7,\n         health_obs = ifelse(pill==1,health_w_pill,health_no_pill))## mutate: new variable 'health_no_pill' (double) with 10,000 unique values and 0% NA\n##         new variable 'health_w_pill' (double) with 10,000 unique values and 0% NA\n## mutate: new variable 'pill' (logical) with 2 unique values and 0% NA\n##         new variable 'health_obs' (double) with 10,000 unique values and 0% NA\nhead(df,10)##       income health_no_pill health_w_pill  pill  health_obs\n## 1  0.9425491    -1.09909844   -0.09909844  TRUE -0.09909844\n## 2  0.3036337     0.39529651    1.39529651 FALSE  0.39529651\n## 3  0.1586546    -0.03096644    0.96903356 FALSE -0.03096644\n## 4  0.7697917     0.80403452    1.80403452  TRUE  1.80403452\n## 5  0.5325691     0.98424526    1.98424526 FALSE  0.98424526\n## 6  0.2626161    -0.42570384    0.57429616 FALSE -0.42570384\n## 7  0.8081499     0.61453339    1.61453339  TRUE  1.61453339\n## 8  0.8546376     2.66338417    3.66338417  TRUE  3.66338417\n## 9  0.3563264    -0.23571357    0.76428643 FALSE -0.23571357\n## 10 0.8094014    -1.19493172   -0.19493172  TRUE -0.19493172\ndf %>%\n  group_by(pill) %>%\n  summarize(health = mean(health_obs))## group_by: one grouping variable (pill)\n## summarize: now 2 rows and 2 columns, ungrouped## # A tibble: 2 × 2\n##   pill  health\n##   <lgl>  <dbl>\n## 1 FALSE  0.360\n## 2 TRUE   1.83\ndf %>%\n  filter(abs(income-.7)<.01) %>%\n  group_by(pill) %>%\n  summarize(health = mean(health_obs)) ## BOOM!!## filter: removed 9,796 rows (98%), 204 rows remaining\n## group_by: one grouping variable (pill)\n## summarize: now 2 rows and 2 columns, ungrouped## # A tibble: 2 × 2\n##   pill  health\n##   <lgl>  <dbl>\n## 1 FALSE  0.557\n## 2 TRUE   1.63"},{"path":"tutorial-2-key-concepts.html","id":"tutorial-2-key-concepts","chapter":"4 Tutorial 2: Key Concepts","heading":"4 Tutorial 2: Key Concepts","text":"","code":""},{"path":"tutorial-2-key-concepts.html","id":"what-is-this-tutorial-about","chapter":"4 Tutorial 2: Key Concepts","heading":"What is this tutorial about?","text":"can access tutorial clicking . tutorial quiz key concepts Chapter 1 “Causal Inference: ” Hernán Robins well Chapter 3 (“Describing Variables”) “Effect” Huntington-Klein.","code":""},{"path":"lecture-2-exercises.html","id":"lecture-2-exercises","chapter":"5 Lecture 2 Exercises","heading":"5 Lecture 2 Exercises","text":"tutorial created John Santos (minor adaptations ).","code":""},{"path":"lecture-2-exercises.html","id":"main-exercise","chapter":"5 Lecture 2 Exercises","heading":"5.1 Main Exercise","text":"data ’fertil2’ collected women living Republic Botswana 1988. variable children refers number living children. variable electric binary indicator equal one woman’s home electricity, zero . Using “fertil2” data {wooldridge}…Find smallest largest values children sample. average children?percentage women electricity home?Compute average children without electricity electricity.part (iii), can infer electricity “causes” women fewer children?() Find smallest largest values children sample. average children?Using Base R…Using describe() function psych package…(ii) percentage women electricity home?Using Base…Using tidyverse conventions…14% women electricity.(iii) Compute average children without electricity electricity.Using Base manually calculate averages subsets…code , translated plain English, something like: “Calculate mean fertil2$children cases fertil2$electric equals 0, removing cases NAs.”code calculates compliment code . plain English, code says, “Calculate mean fertil2$children cases fertil2$electric equals 1, removing cases NAs.”Mean number children among women without electricity = 2.33.Mean number children among women electricity = 1.90.also use t.test() command Base R:Mean difference = 0.43, \\(p\\leq0.001\\), 95% CI = 0.27 0.59.average, women electricity 0.43 fewer children women without electricity, difference statistically significant.(iv) part (iii), can infer electricity “causes” women fewer children?women electricity, average, fewer children women without electricity, relationship statistically significant, necessarily infer electricity “causes” women fewer children. need mechanism link electricity children conclude electricity cause.Perhaps, electricity spurious common cause SES.","code":"\nlibrary(wooldridge)\nlibrary(tidyverse)\nlibrary(psych)\ndata(\"fertil2\")\nmin(fertil2$children)## [1] 0\nmax(fertil2$children)## [1] 13\nmean(fertil2$children)## [1] 2.267828\nsummary(fertil2$children)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   0.000   0.000   2.000   2.268   4.000  13.000\ndescribe(fertil2$children)##    vars    n mean   sd median trimmed  mad min max range skew kurtosis   se\n## X1    1 4361 2.27 2.22      2    1.95 2.97   0  13    13 1.07     0.75 0.03\nprop.table(table(fertil2$electric))## \n##         0         1 \n## 0.8597981 0.1402019\nfertil2%>%\n  select(electric)%>%\n  table()/nrow(fertil2)## select: dropped 26 variables (mnthborn, yearborn, age, radio, tv, …)## electric\n##         0         1 \n## 0.8592066 0.1401055\nmean(fertil2$children[fertil2$electric==0], na.rm = TRUE)## [1] 2.327729\nmean(fertil2$children[fertil2$electric==1], na.rm = TRUE)## [1] 1.898527\nt.test(fertil2$children ~ fertil2$electric)## \n##  Welch Two Sample t-test\n## \n## data:  fertil2$children by fertil2$electric\n## t = 5.2409, df = 958, p-value = 1.965e-07\n## alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n## 95 percent confidence interval:\n##  0.2684895 0.5899142\n## sample estimates:\n## mean in group 0 mean in group 1 \n##        2.327729        1.898527\n# dplyr\nlibrary(dplyr)\nfertil2 %>%\n  group_by(electric) %>%\n  summarise(mean = mean(children),\n            sd = sd(children))## group_by: one grouping variable (electric)\n## summarise: now 3 rows and 3 columns, ungrouped## # A tibble: 3 × 3\n##   electric  mean    sd\n##      <int> <dbl> <dbl>\n## 1        0  2.33  2.28\n## 2        1  1.90  1.80\n## 3       NA  2.67  2.89"},{"path":"lecture-2-exercises.html","id":"additional-exercises","chapter":"5 Lecture 2 Exercises","heading":"5.2 Additional Exercises:","text":"Use {ces.Rda} data found .Overall ratings TrudeauThe variables feel_trudeau feeling thermometer ratings Liberal Leader Justin Trudeau. average, Canadians rate ? ’s lowest rating? ’s highest rating?Trudeau ratings groupsDo Trudeau’s ratings vary across groups population? Specifically, look gender (gender), age (agegrp), education (educ).variable (leftrightgrp) measures whether individual places left (0-4), centre (5), right (6-10) political spectrum. ratings Trudeau vary across self-placed ideological categories?","code":""},{"path":"lecture-2-exercises.html","id":"stop","chapter":"5 Lecture 2 Exercises","heading":"5.2.1 STOP!!","text":"continue, try solving exercises . ’s way learn. , come back page see well .","code":""},{"path":"lecture-2-exercises.html","id":"continue","chapter":"5 Lecture 2 Exercises","heading":"5.2.2 Continue","text":"","code":"\nload(\"Sample_data/ces.Rda\")"},{"path":"lecture-2-exercises.html","id":"overall-ratings-of-trudeau","chapter":"5 Lecture 2 Exercises","heading":"5.2.3 Overall ratings of Trudeau","text":"variable feel_trudeau feeling thermometer ratings Liberal Leader Justin Trudeau. average, Canadians rate ? ’s lowest rating? ’s highest rating?Using base R.D’oh! didn’t work NAs.Let’s remove using option na.rm = TRUE.Alternatively, can use summary() command.can using dplyr. can use method calculate summary statistics time.also calculate statistics…","code":"\nmean(ces$feel_trudeau)## [1] NA\nmin(ces$feel_trudeau)## [1] NA\nmax(ces$feel_trudeau)## [1] NA\nmean(ces$feel_trudeau, na.rm = TRUE)## [1] 44.84804\nmin(ces$feel_trudeau, na.rm = TRUE)## [1] 0\nmax(ces$feel_trudeau, na.rm = TRUE)## [1] 100\nsummary(ces$feel_trudeau)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##    0.00    7.00   50.00   44.85   75.00  100.00    2409\nlibrary(dplyr)\nces %>%\n  summarise(mean = mean(feel_trudeau, na.rm = TRUE),\n            min = min(feel_trudeau, na.rm = TRUE),\n            max = max(feel_trudeau, na.rm = TRUE))## summarise: now one row and 3 columns, ungrouped##       mean min max\n## 1 44.84804   0 100\nces %>%\n  summarise(mean = mean(feel_trudeau, na.rm = TRUE),\n            median = median(feel_trudeau, na.rm = TRUE),\n            min = min(feel_trudeau, na.rm = TRUE),\n            max = max(feel_trudeau, na.rm = TRUE),\n            sd = sd(feel_trudeau, na.rm = TRUE),\n            se = sd(feel_trudeau, na.rm = TRUE) / sqrt(sum(!is.na(feel_trudeau))),\n            lower95 = mean - (1.96*se),\n            upper95 = mean + (1.96*se)) ## summarise: now one row and 8 columns, ungrouped##       mean median min max       sd        se  lower95 upper95\n## 1 44.84804     50   0 100 34.54668 0.1838109 44.48777 45.2083"},{"path":"lecture-2-exercises.html","id":"trudeau-ratings-by-groups","chapter":"5 Lecture 2 Exercises","heading":"5.2.4 Trudeau ratings by groups","text":"Trudeau’s ratings vary across groups population? look gender (gender), age (agegrp), education (educ). variable (leftrightgrp) measures whether individual places left (0-4), centre (5), right (6-10) political spectrum. ratings Trudeau vary across self-placed ideological categories?","code":""},{"path":"lecture-2-exercises.html","id":"gender","chapter":"5 Lecture 2 Exercises","heading":"5.2.5 Gender","text":"Using dplyr…can also use base R command t.test().option somewhat limited works comparing across two categories. However, test significance difference, useful.","code":"\nmean(ces$feel_trudeau[ces$gender==\"Man\"], na.rm=T)## [1] 43.35218\nmean(ces$feel_trudeau[ces$gender==\"Woman\"], na.rm=T)## [1] 45.93724\nt.test(ces$feel_trudeau ~ ces$gender)## \n##  Welch Two Sample t-test\n## \n## data:  ces$feel_trudeau by ces$gender\n## t = -6.9009, df = 31483, p-value = 5.266e-12\n## alternative hypothesis: true difference in means between group Man and group Woman is not equal to 0\n## 95 percent confidence interval:\n##  -3.319280 -1.850828\n## sample estimates:\n##   mean in group Man mean in group Woman \n##            43.35218            45.93724\nces %>%\n  group_by(gender) %>%\n  summarise(avg = mean(feel_trudeau, na.rm = TRUE))## group_by: one grouping variable (gender)\n## summarise: now 3 rows and 2 columns, ungrouped## # A tibble: 3 × 2\n##   gender   avg\n##   <fct>  <dbl>\n## 1 Man     43.4\n## 2 Woman   45.9\n## 3 <NA>    44.8\nt.test(ces$feel_trudeau ~ ces$gender, na.rm = TRUE)## \n##  Welch Two Sample t-test\n## \n## data:  ces$feel_trudeau by ces$gender\n## t = -6.9009, df = 31483, p-value = 5.266e-12\n## alternative hypothesis: true difference in means between group Man and group Woman is not equal to 0\n## 95 percent confidence interval:\n##  -3.319280 -1.850828\n## sample estimates:\n##   mean in group Man mean in group Woman \n##            43.35218            45.93724"},{"path":"lecture-2-exercises.html","id":"age","chapter":"5 Lecture 2 Exercises","heading":"5.2.5.1 Age","text":"","code":"\nces %>%\n  group_by(agegrp) %>%\n  summarise(avg = mean(feel_trudeau, na.rm = TRUE))## group_by: one grouping variable (agegrp)\n## summarise: now 3 rows and 2 columns, ungrouped## # A tibble: 3 × 2\n##   agegrp   avg\n##   <fct>  <dbl>\n## 1 18-34   49.1\n## 2 35-54   43.2\n## 3 55+     43.7"},{"path":"lecture-2-exercises.html","id":"education","chapter":"5 Lecture 2 Exercises","heading":"5.2.5.2 Education","text":"","code":"\nces %>%\n  group_by(educ) %>%\n  summarise(avg = mean(feel_trudeau, na.rm = TRUE))## group_by: one grouping variable (educ)\n## summarise: now 5 rows and 2 columns, ungrouped## # A tibble: 5 × 2\n##   educ         avg\n##   <fct>      <dbl>\n## 1 HS or less  38.0\n## 2 Some PSE    42.3\n## 3 Bachelors   51.3\n## 4 Postgrad    52.1\n## 5 <NA>        38.1"},{"path":"lecture-2-exercises.html","id":"ideology","chapter":"5 Lecture 2 Exercises","heading":"5.2.5.3 Ideology","text":"","code":"\nces %>%\n  group_by(leftrightgrp) %>%\n  summarise(avg = mean(feel_trudeau, na.rm = TRUE))## group_by: one grouping variable (leftrightgrp)\n## summarise: now 4 rows and 2 columns, ungrouped## # A tibble: 4 × 2\n##   leftrightgrp   avg\n##   <fct>        <dbl>\n## 1 Left          59.4\n## 2 Centre        42.9\n## 3 Right         37.8\n## 4 <NA>          43.6"},{"path":"lecture-3-core-concepts-of-experimental-design.html","id":"lecture-3-core-concepts-of-experimental-design","chapter":"6 Lecture 3: Core Concepts of Experimental Design","heading":"6 Lecture 3: Core Concepts of Experimental Design","text":"","code":""},{"path":"lecture-3-core-concepts-of-experimental-design.html","id":"slides-2","chapter":"6 Lecture 3: Core Concepts of Experimental Design","heading":"Slides","text":"4 Core Concepts Experimental Design (link)","code":""},{"path":"lecture-3-core-concepts-of-experimental-design.html","id":"introduction-2","chapter":"6 Lecture 3: Core Concepts of Experimental Design","heading":"6.1 Introduction","text":"lecture look (slightly) technical understanding selection bias (understand problem observational data) potential outcomes approach (understand random assignment solves problem).lecture slide displayed full :\nFigure 6.1: Slides 4 Core Concepts Experimental Design.\n","code":""},{"path":"lecture-3-core-concepts-of-experimental-design.html","id":"vignette-3.1","chapter":"6 Lecture 3: Core Concepts of Experimental Design","heading":"6.2 Vignette 3.1","text":"Liebman, Jeffrey B., Erzo FP Luttmer. “people behave differently better understood social security? Evidence field experiment.” American Economic Journal: Economic Policy 7.1 (2015): 275-99.variable interest (DV, Y) paid_work_yes: whether person worked . treatment variable treat: whether got pamphlet . experiment, can compare averages treatment group control group estimate causal effect.effect reported authors!! can also estimate differences gender (?):Treatment effect women… ?averages look great can sure effects mere coincidence product randomization? Let’s add confidence intervals:now gender:Cool…","code":"\nlibrary(tidyverse) # for wrangling data\nlibrary(tidylog) # to know what we are wrangling\nlibrary(sjPlot) # to plot somse models\nlibrary(readstata13) # to load .dta files\nexp_data %>%\n  group_by(treat) %>% \n  summarise(ATE = mean(paid_work_yes, na.rm = T))## group_by: one grouping variable (treat)\n## summarise: now 2 rows and 2 columns, ungrouped## # A tibble: 2 × 2\n##   treat   ATE\n##   <dbl> <dbl>\n## 1     0 0.744\n## 2     1 0.785\nexp_data %>%\n  group_by(female,treat) %>% \n  summarise(ATE = mean(paid_work_yes, na.rm = T))## group_by: 2 grouping variables (female, treat)\n## summarise: now 4 rows and 3 columns, one group variable remaining (female)## # A tibble: 4 × 3\n## # Groups:   female [2]\n##   female treat   ATE\n##    <int> <dbl> <dbl>\n## 1      0     0 0.784\n## 2      0     1 0.787\n## 3      1     0 0.713\n## 4      1     1 0.782\nexp_data$treat <- as.factor(exp_data$treat)\nexp_data$female <- as.factor(exp_data$female)\n\n# Full model\nmodel_1 <- lm(paid_work_yes ~ treat, data = exp_data)\nsummary(model_1)## \n## Call:\n## lm(formula = paid_work_yes ~ treat, data = exp_data)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -0.7845  0.2155  0.2155  0.2555  0.2555 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  0.74446    0.01530  48.666   <2e-16 ***\n## treat1       0.04004    0.02124   1.885   0.0596 .  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.4237 on 1591 degrees of freedom\n##   (890 observations deleted due to missingness)\n## Multiple R-squared:  0.002228,   Adjusted R-squared:  0.001601 \n## F-statistic: 3.553 on 1 and 1591 DF,  p-value: 0.05961\nplot_model(model_1, type = \"pred\", terms = \"treat\") +\n  theme_minimal() +\n  labs(x=\"Treatment\", y=\"Worked +1 Year\",\n       title=\"Predicted Effect of Treatment\")\n# Model by gender\nmodel_2 <- lm(paid_work_yes ~ female + treat + female*treat, data = exp_data)\nsummary(model_2)## \n## Call:\n## lm(formula = paid_work_yes ~ female + treat + female * treat, \n##     data = exp_data)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -0.7871  0.2129  0.2164  0.2176  0.2871 \n## \n## Coefficients:\n##                 Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)     0.783626   0.022885  34.242   <2e-16 ***\n## female1        -0.070685   0.030743  -2.299   0.0216 *  \n## treat1          0.003436   0.031725   0.108   0.9138    \n## female1:treat1  0.066040   0.042680   1.547   0.1220    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.4232 on 1589 degrees of freedom\n##   (890 observations deleted due to missingness)\n## Multiple R-squared:  0.005552,   Adjusted R-squared:  0.003675 \n## F-statistic: 2.957 on 3 and 1589 DF,  p-value: 0.03136\nplot_model(model_2, type = \"int\") +\n  theme_minimal() +\n  labs(x=\"Women\", y=\"Worked +1 Year\", color = \"Treatment\",\n       title=\"Predicted Effect of Treatment by Gender\")"},{"path":"tutorial-3-more-key-concepts.html","id":"tutorial-3-more-key-concepts","chapter":"7 Tutorial 3: More Key Concepts","heading":"7 Tutorial 3: More Key Concepts","text":"","code":""},{"path":"tutorial-3-more-key-concepts.html","id":"what-is-this-tutorial-about-1","chapter":"7 Tutorial 3: More Key Concepts","heading":"What is this tutorial about?","text":"can access tutorial clicking . tutorial test understanding key concepts Chapter 2 “Causal Inference: ” Hernán Robins, focusing randomized experiments. ’ll engage theoretical concepts practical data analysis.","code":""},{"path":"lecture-3-exercises.html","id":"lecture-3-exercises","chapter":"8 Lecture 3 Exercises","heading":"8 Lecture 3 Exercises","text":"tutorial created John Santos (minor adaptations ).start exercises, take look dplyr pipping.","code":""},{"path":"lecture-3-exercises.html","id":"dplyr-primer","chapter":"8 Lecture 3 Exercises","heading":"8.1 {dplyr} primer","text":"dplyr R package part tidyverse family packages. tidyverse provides unified “grammar” coding, opposed idiosyncratic conventions Base R.dplyr focuses data management/transformation.purposes, used dplyr functions include:select(): pick column (.e. variable) multiple columns data frame.mutate(): create new column.summarise(): create new column calculated existing column.group_by(): precedes summarise() command tells R column want summarise.filter(): pick rows (.e. cases) according criterion/criteria.nifty thing dplyr (tidyverse generally) use “pipelines,” created using pipe operator, %>%. means need identify data frame working “pipe ” “pipeline operations”, saves time reduces chance coding errors.(Note: RStudio also “native pipe operator”, |>, works newer versions R yet universally adopted.)","code":""},{"path":"lecture-3-exercises.html","id":"the-select-command-in-action","chapter":"8 Lecture 3 Exercises","heading":"8.1.1 The select() command in action","text":"Say wanted pick feeling thermometer questions sample CES data set.column names:Let’s pull columns using Base R put new data frame called “feelings_base”. ’m feeling lazy, ’m just going parties.also pull columns using index numbers, isn’t recommended index numbers change depending version data set previous operations performed .dplyr way efficient:get even fancier use starts_with() command select every column whose column name starts character string “feel_”:","code":"\nload(\"Sample_data/ces.rda\")\nnames(ces)##  [1] \"weight\"        \"age\"           \"agegrp\"        \"age_18to34\"    \"age_35to54\"    \"age_55plus\"    \"gender\"        \"woman\"         \"lang\"         \n## [10] \"province\"      \"region\"        \"reg_on\"        \"reg_qc\"        \"reg_atl\"       \"reg_west\"      \"educ\"          \"univ\"          \"relig\"        \n## [19] \"rel_catholic\"  \"rel_christian\" \"rel_other\"     \"rel_none\"      \"income\"        \"incomegrp\"     \"mostimp\"       \"turnout\"       \"leftright\"    \n## [28] \"leftrightgrp\"  \"lr_left\"       \"lr_centre\"     \"lr_right\"      \"feel_lib\"      \"feel_cpc\"      \"feel_ndp\"      \"feel_bloc\"     \"feel_green\"   \n## [37] \"feel_ppc\"      \"feel_trudeau\"  \"feel_scheer\"   \"feel_singh\"    \"feel_blanchet\" \"feel_may\"      \"feel_bernier\"  \"polinterest\"   \"marketlib\"    \n## [46] \"moraltrad\"     \"helpgroups\"\nfeelings_base <- data.frame(\n  feel_lib = ces$feel_lib,\n  feel_cpc = ces$feel_cpc,\n  feel_ndp = ces$feel_ndp,\n  feel_bloc = ces$feel_bloc,\n  feel_green = ces$feel_green,\n  feel_ppc = ces$feel_ppc\n)\nhead(feelings_base)##   feel_lib feel_cpc feel_ndp feel_bloc feel_green feel_ppc\n## 1       52        0       64        NA         97        0\n## 2       51        0       64        40         88        0\n## 3       52       49       NA        NA         NA       NA\n## 4       30       85        0         0          0       30\n## 5       20       62       51        20         50       20\n## 6       81       31       79        NA         85        0\nfeelings_numsel <- ces[32:43]\nhead(feelings_numsel)##   feel_lib feel_cpc feel_ndp feel_bloc feel_green feel_ppc feel_trudeau feel_scheer feel_singh feel_blanchet feel_may feel_bernier\n## 1       52        0       64        NA         97        0           55           0         71            15       80            0\n## 2       51        0       64        40         88        0           53           0         NA            32       59            0\n## 3       52       49       NA        NA         NA       NA           74          24         63            NA       56           20\n## 4       30       85        0         0          0       30            0          80          0             0        0           10\n## 5       20       62       51        20         50       20           30          60         NA            50       60           30\n## 6       81       31       79        NA         85        0           81          35         70            NA       74            3\nlibrary(dplyr)\nfeelings_dplyr <- select(ces, c(feel_lib:feel_blanchet))## select: dropped 37 variables (weight, age, agegrp, age_18to34, age_35to54, …)\nhead(feelings_dplyr)##   feel_lib feel_cpc feel_ndp feel_bloc feel_green feel_ppc feel_trudeau feel_scheer feel_singh feel_blanchet\n## 1       52        0       64        NA         97        0           55           0         71            15\n## 2       51        0       64        40         88        0           53           0         NA            32\n## 3       52       49       NA        NA         NA       NA           74          24         63            NA\n## 4       30       85        0         0          0       30            0          80          0             0\n## 5       20       62       51        20         50       20           30          60         NA            50\n## 6       81       31       79        NA         85        0           81          35         70            NA\nfeelings_dplyr2 <- select(ces, starts_with(\"feel_\"))## select: dropped 35 variables (weight, age, agegrp, age_18to34, age_35to54, …)\nhead(feelings_dplyr2)##   feel_lib feel_cpc feel_ndp feel_bloc feel_green feel_ppc feel_trudeau feel_scheer feel_singh feel_blanchet feel_may feel_bernier\n## 1       52        0       64        NA         97        0           55           0         71            15       80            0\n## 2       51        0       64        40         88        0           53           0         NA            32       59            0\n## 3       52       49       NA        NA         NA       NA           74          24         63            NA       56           20\n## 4       30       85        0         0          0       30            0          80          0             0        0           10\n## 5       20       62       51        20         50       20           30          60         NA            50       60           30\n## 6       81       31       79        NA         85        0           81          35         70            NA       74            3"},{"path":"lecture-3-exercises.html","id":"using-summarise-to-calculate-summary-statistics","chapter":"8 Lecture 3 Exercises","heading":"8.1.2 Using {summarise} to calculate summary statistics","text":"Let’s say want calculate sample mean feeling thermometer score. Base, might something like following, separate line code calculation. (, ’m lazy, ’ve done three, 12 lines total.)dplyr way efficient, thanks %>% operator, allows us write name data frame “pipe ” entire chain commands.","code":"\nmean(ces$feel_lib, na.rm = TRUE)## [1] 48.34366\nmean(ces$feel_cpc, na.rm = TRUE)## [1] 43.61424\nmean(ces$feel_ndp, na.rm = TRUE)## [1] 50.03684\nces %>%\n  select(starts_with(\"feel_\")) %>%\n  summarise(across(everything(), \n                   list(mean), \n                   na.rm = TRUE))## select: dropped 35 variables (weight, age, agegrp, age_18to34, age_35to54, …)\n## summarise: now one row and 12 columns, ungrouped##   feel_lib_1 feel_cpc_1 feel_ndp_1 feel_bloc_1 feel_green_1 feel_ppc_1 feel_trudeau_1 feel_scheer_1 feel_singh_1 feel_blanchet_1 feel_may_1 feel_bernier_1\n## 1   48.34366   43.61424   50.03684    23.33321     47.45785   25.81046       44.84804      39.51979     50.36898        27.79471   46.85782       26.14414"},{"path":"lecture-3-exercises.html","id":"the-group_by-and-summarise-combo","chapter":"8 Lecture 3 Exercises","heading":"8.1.3 The {group_by} and {summarise} combo","text":"Calculating group-wise summary statistics Base bit clunky. Recall last week, Base R uses square brackets selection subsetting. want calculate average rating PPC among Western Canadians versus everyone else, something like :dplyr way :first, might think dplyr way longer three instead two lines code. However, efficient less duplication code.dplyr really starts show advantage performan many calculations (variables, groupings, /summary statistics).want calculate dispersion distributions (SD) uncertainty associated estimated means (SE), looks like Base R:dplyr way:","code":"\nmean(ces$feel_ppc[ces$reg_west==1], na.rm = TRUE)## [1] 27.04223\nmean(ces$feel_ppc[ces$reg_west==0], na.rm = TRUE)## [1] 25.25404\nces %>%\n  group_by(reg_west) %>% \n  summarise(mean_ppc = mean(feel_ppc, na.rm = TRUE))## group_by: one grouping variable (reg_west)\n## summarise: now 2 rows and 2 columns, ungrouped## # A tibble: 2 × 2\n##   reg_west mean_ppc\n##      <dbl>    <dbl>\n## 1        0     25.3\n## 2        1     27.0\nsd(ces$feel_ppc[ces$reg_west==1], na.rm = TRUE)## [1] 26.75502\nsd(ces$feel_ppc[ces$reg_west==0], na.rm = TRUE)## [1] 26.43218\nsd(ces$feel_ppc[ces$reg_west==1], na.rm = TRUE) / \n  sqrt(sum(!is.na(ces$feel_ppc[ces$reg_west==1])))## [1] 0.2654482\nsd(ces$feel_ppc[ces$reg_west==0], na.rm = TRUE) / \n  sqrt(sum(!is.na(ces$feel_ppc[ces$reg_west==0])))## [1] 0.1762576\nces %>%\n  group_by(reg_west) %>% \n  summarise(mean_ppc = mean(feel_ppc, na.rm = TRUE),\n            sd_ppc = sd(feel_ppc, na.rm = TRUE),\n            n_ppc = sum(!is.na(feel_ppc)),\n            semean_ppc = sd_ppc / sqrt(n_ppc)\n            )## group_by: one grouping variable (reg_west)\n## summarise: now 2 rows and 5 columns, ungrouped## # A tibble: 2 × 5\n##   reg_west mean_ppc sd_ppc n_ppc semean_ppc\n##      <dbl>    <dbl>  <dbl> <int>      <dbl>\n## 1        0     25.3   26.4 22489      0.176\n## 2        1     27.0   26.8 10159      0.265"},{"path":"lecture-3-exercises.html","id":"lecture-3-exercises-1","chapter":"8 Lecture 3 Exercises","heading":"8.2 Lecture 3 Exercises","text":"Using ’fertil2’ dataset ’wooldridge’ women living Republic Botswana 1988,() Calculate means mean differences without electricity following two characteristics:education (educ)age first child born (agefbrth)’ll start loading dataset.loading dataset, let’s look summary statistics (also known descriptive statistics simply descriptives) variables ’re analyze. looking , keep mine units analysis whether missing values deal analyze data.Now can calculate summary statistics group two variables.Difference education attainment without (0) (1) electricity.Without (0) = 5.382 yearsWith (1) = 8.763 yearsDifference = 8.763 - 5.382 == 3.381 years schooling(Note: isn’t important now, average among NAs group often indicates missingness bias results. later methods courses, ’ll learn ways test deal .)Difference age first child born without (0) (1) electricity.Without (0) = 18.825 years oldWith (1) = 20.162 years oldDifference = 20.162 - 18.825 == 1.337 years old(ii) Evaluate mean differences statistically significant 0.01 0.05 levels.education, difference means = 3.381 years, p = 2.2*10^-16 (less 0.001), difference significant 0.05 0.01 levels. fact, even significant 0.001 level.Using confidence interval approach, also say 95% confidence interval difference -3.720 -3.041, include zero. indicates difference statistically significant 0.05 level.code uses “formula notation”, quantitative variable listed first, tilde (“~”), categorical variable.use formula notation incorrect order, won’t work, following case: t.test(fertil2$electric ~ fertil2$agefbrth).Specifying “vector notation” specifying two complementary subsets (using square brackets, []) also works. vector notation approach works regardless order specify two vectors, can seen example :Regardless approach use, age birth first child, difference means = 1.337 years (p = 1.432*10^-13). , difference significant 0.05 0.01 levels. fact, even significant 0.001 level.Using confidence interval approach, also say 95% confidence interval difference -1.683 -0.990, include zero. indicates difference statistically significant 0.05 level.note Stata users: default, t.test() uses unequal variances (proposed Welch). possible perform “vanilla” Student’s t-test assumes equal variances specifying option var.equal = TRUE. However, practice, reason . Welch’s t-test robust Student’s t-test assumptions test violated, performs just well (rare) cases assumptions met. compare results R Stata, t-tests usually match Stata, default, assumes equal variances. can get Stata assume unequal variances specifying option (e.g. ttest agefbrth, (electric) unequal welch).(iii) Interpret results.Women access electricity , average, 3.4 years education 1.3 years younger women access electricity. mean differences significant 0.01 0.05 levels.(iv) analysis, say comparisons women without electricity apples--apples apples--oranges?apples--oranges comparisons.(v) affect ability conclude anything relationship access electricity number children?previous exercise, found women access electricity , average, fewer children women access electricity (mean difference = 0.43 children, p<0.001). Women electricity systematically different women without electricity terms children, children later, years schooling. Presumably, children, children, years schooling also related. , sure true link access electricity number children woman without controlling factors.","code":"\nlibrary(wooldridge)\ncupcakes <- get(data('fertil2'))\nhead(cupcakes)##   mnthborn yearborn age electric radio tv bicycle educ ceb agefbrth children knowmeth usemeth monthfm yearfm agefm idlnchld heduc agesq urban urb_educ spirit\n## 1        5       64  24        1     1  1       1   12   0       NA        0        1       0      NA     NA    NA        2    NA   576     1       12      0\n## 2        1       56  32        1     1  1       1   13   3       25        3        1       1      11     80    24        3    12  1024     1       13      0\n## 3        7       58  30        1     0  0       0    5   1       27        1        1       0       6     83    24        5     7   900     1        5      1\n## 4       11       45  42        1     0  1       0    4   3       17        2        1       0       1     61    15        3    11  1764     1        4      0\n## 5        5       45  43        1     1  1       1   11   2       24        2        1       1       3     66    20        2    14  1849     1       11      0\n## 6        8       52  36        1     0  0       0    7   1       26        1        1       1      11     76    24        4     9  1296     1        7      0\n##   protest catholic frsthalf educ0 evermarr\n## 1       0        0        1     0        0\n## 2       0        0        1     0        1\n## 3       0        0        0     0        1\n## 4       0        0        0     0        1\n## 5       1        0        1     0        1\n## 6       0        0        0     0        1\ndata(\"fertil2\")\nhead(fertil2)##   mnthborn yearborn age electric radio tv bicycle educ ceb agefbrth children knowmeth usemeth monthfm yearfm agefm idlnchld heduc agesq urban urb_educ spirit\n## 1        5       64  24        1     1  1       1   12   0       NA        0        1       0      NA     NA    NA        2    NA   576     1       12      0\n## 2        1       56  32        1     1  1       1   13   3       25        3        1       1      11     80    24        3    12  1024     1       13      0\n## 3        7       58  30        1     0  0       0    5   1       27        1        1       0       6     83    24        5     7   900     1        5      1\n## 4       11       45  42        1     0  1       0    4   3       17        2        1       0       1     61    15        3    11  1764     1        4      0\n## 5        5       45  43        1     1  1       1   11   2       24        2        1       1       3     66    20        2    14  1849     1       11      0\n## 6        8       52  36        1     0  0       0    7   1       26        1        1       1      11     76    24        4     9  1296     1        7      0\n##   protest catholic frsthalf educ0 evermarr\n## 1       0        0        1     0        0\n## 2       0        0        1     0        1\n## 3       0        0        0     0        1\n## 4       0        0        0     0        1\n## 5       1        0        1     0        1\n## 6       0        0        0     0        1\nsummary(fertil2$electric)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##  0.0000  0.0000  0.0000  0.1402  0.0000  1.0000       3\nsummary(fertil2$educ)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   0.000   3.000   7.000   5.856   8.000  20.000\nsummary(fertil2$agefbrth)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##   10.00   17.00   19.00   19.01   20.00   38.00    1088\nlibrary(dplyr)\nfertil2 %>%\n  group_by(electric) %>%\n  summarise(mean_educ = mean(educ, na.rm = TRUE))## group_by: one grouping variable (electric)\n## summarise: now 3 rows and 2 columns, ungrouped## # A tibble: 3 × 2\n##   electric mean_educ\n##      <int>     <dbl>\n## 1        0      5.38\n## 2        1      8.76\n## 3       NA      5.67\nfertil2 %>%\n  group_by(electric) %>%\n  summarise(mean_agefbrth = mean(agefbrth, na.rm = TRUE))## group_by: one grouping variable (electric)\n## summarise: now 3 rows and 2 columns, ungrouped## # A tibble: 3 × 2\n##   electric mean_agefbrth\n##      <int>         <dbl>\n## 1        0          18.8\n## 2        1          20.2\n## 3       NA          18\nt.test(fertil2$educ ~ fertil2$electric)## \n##  Welch Two Sample t-test\n## \n## data:  fertil2$educ by fertil2$electric\n## t = -19.569, df = 790.18, p-value < 2.2e-16\n## alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n## 95 percent confidence interval:\n##  -3.719608 -3.041416\n## sample estimates:\n## mean in group 0 mean in group 1 \n##        5.382172        8.762684\nt.test(fertil2$agefbrth ~ fertil2$electric)## \n##  Welch Two Sample t-test\n## \n## data:  fertil2$agefbrth by fertil2$electric\n## t = -7.5801, df = 562.66, p-value = 1.432e-13\n## alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n## 95 percent confidence interval:\n##  -1.6827861 -0.9901586\n## sample estimates:\n## mean in group 0 mean in group 1 \n##        18.82545        20.16193\nt.test(fertil2$agefbrth[fertil2$electric==1],fertil2$agefbrth[fertil2$electric==0])## \n##  Welch Two Sample t-test\n## \n## data:  fertil2$agefbrth[fertil2$electric == 1] and fertil2$agefbrth[fertil2$electric == 0]\n## t = 7.5801, df = 562.66, p-value = 1.432e-13\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  0.9901586 1.6827861\n## sample estimates:\n## mean of x mean of y \n##  20.16193  18.82545\nt.test(fertil2$agefbrth[fertil2$electric==0],fertil2$agefbrth[fertil2$electric==1])## \n##  Welch Two Sample t-test\n## \n## data:  fertil2$agefbrth[fertil2$electric == 0] and fertil2$agefbrth[fertil2$electric == 1]\n## t = -7.5801, df = 562.66, p-value = 1.432e-13\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  -1.6827861 -0.9901586\n## sample estimates:\n## mean of x mean of y \n##  18.82545  20.16193\nfertil2 %>%\n  select(c(electric, educ, agefbrth)) %>%\n  filter(!is.na(electric)) %>%\n  group_by(electric) %>%\n  summarise(mean_agefbrth = mean(agefbrth, na.rm = TRUE),\n            mean_educ = mean(educ, na.rm = TRUE)) %>%\n  mutate(electric = factor(electric,\n                           levels = c(0,1),\n                           labels = c(\"No electricity\",\n                                      \"Electricity\")))## select: dropped 24 variables (mnthborn, yearborn, age, radio, tv, …)\n## filter: removed 3 rows (<1%), 4,358 rows remaining\n## group_by: one grouping variable (electric)\n## summarise: now 2 rows and 3 columns, ungrouped\n## mutate: converted 'electric' from integer to factor (0 new NA)## # A tibble: 2 × 3\n##   electric       mean_agefbrth mean_educ\n##   <fct>                  <dbl>     <dbl>\n## 1 No electricity          18.8      5.38\n## 2 Electricity             20.2      8.76"},{"path":"lecture-3-exercises.html","id":"additional-exercises-1","chapter":"8 Lecture 3 Exercises","heading":"8.3 Additional Exercises:","text":"Using ‘ces’ dataset, calculate means mean differences support market liberalism (marketlib) across whether someone lives Western Canada (reg_west) men women (gender);evaluate mean differences statistically significant 0.01 0.05 levels;interpret results way practice exercises lecture;","code":""},{"path":"lecture-3-exercises.html","id":"stop-1","chapter":"8 Lecture 3 Exercises","heading":"8.3.1 STOP!!","text":"continue, try solving exercises . ’s way learn. , come back page see well .","code":""},{"path":"lecture-3-exercises.html","id":"continue-1","chapter":"8 Lecture 3 Exercises","heading":"8.3.2 Continue","text":"’ll start loading dataset taking look univariate summaries variable ’ll analyzing.Market liberalism measured scale 0 16 points, average 8.59.Region West gender binary variables.NAs marketlib gender.","code":"\nload(\"Sample_data/ces.rda\")\nsummary(ces$marketlib)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##    0.00    6.00    9.00    8.59   11.00   16.00   32684\nsummary(ces$reg_west)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##  0.0000  0.0000  0.0000  0.3145  1.0000  1.0000\nsummary(ces$gender)##   Man Woman  NA's \n## 15517 21928   288"},{"path":"lecture-3-exercises.html","id":"group-wise-means-mean-differences-and-statistical-significance","chapter":"8 Lecture 3 Exercises","heading":"8.3.3 Group-wise means, mean differences, and statistical significance","text":"’m going use t.test() get significance testing. dplyr version follows, want see .Among live Western Canada, average market liberalism score 8.748. Among live Western Canada, score 8.498. means , average, living Western Canada 0.25 points 16 supportive market liberalism living elsewhere country. difference significant 0.05 level (p=0.018).Among men, average market liberalism score 9.079. Among women, score 8.156. means , average, men living Western Canada 0.923 points 16 supportive market liberalism women. difference significant 0.001 level (p=<0.001).dplyr version:","code":"\nt.test(ces$marketlib ~ ces$reg_west)## \n##  Welch Two Sample t-test\n## \n## data:  ces$marketlib by ces$reg_west\n## t = -2.3712, df = 3428.5, p-value = 0.01779\n## alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n## 95 percent confidence interval:\n##  -0.4571754 -0.0433279\n## sample estimates:\n## mean in group 0 mean in group 1 \n##        8.498180        8.748431\nt.test(ces$marketlib ~ ces$gender)## \n##  Welch Two Sample t-test\n## \n## data:  ces$marketlib by ces$gender\n## t = 9.4086, df = 5012.2, p-value < 2.2e-16\n## alternative hypothesis: true difference in means between group Man and group Woman is not equal to 0\n## 95 percent confidence interval:\n##  0.7309037 1.1156689\n## sample estimates:\n##   mean in group Man mean in group Woman \n##            9.079404            8.156118\nces %>%\n  group_by(reg_west) %>% \n  summarise(mean_marketlib = mean(marketlib, na.rm = TRUE))## group_by: one grouping variable (reg_west)\n## summarise: now 2 rows and 2 columns, ungrouped## # A tibble: 2 × 2\n##   reg_west mean_marketlib\n##      <dbl>          <dbl>\n## 1        0           8.50\n## 2        1           8.75\nces %>%\n  group_by(gender) %>% \n  summarise(mean_marketlib = mean(marketlib, na.rm = TRUE))## group_by: one grouping variable (gender)\n## summarise: now 3 rows and 2 columns, ungrouped## # A tibble: 3 × 2\n##   gender mean_marketlib\n##   <fct>           <dbl>\n## 1 Man              9.08\n## 2 Woman            8.16\n## 3 <NA>             5.38"},{"path":"lecture-3-exercises.html","id":"interpretation-of-results","chapter":"8 Lecture 3 Exercises","heading":"8.3.4 Interpretation of results","text":"Among sets comparisons statistically significant differences support principle market liberalism. However, gender region, necessarily conclude ’ve solved reason Westerners supportive free market Canadians men supportive free market women. Moreover, region, magnitude difference quarter point 16 scale, dubious substantive significance.variables usually referred demographic characteristics, personal attributes individual. tend “far back” processes lead outcomes interest political science (like policy preferences vote choice) often exert effect intervening variables, things come -personal characteristics outcomes.","code":""},{"path":"lecture-4-the-simple-regression-model-i.html","id":"lecture-4-the-simple-regression-model-i","chapter":"9 Lecture 4: The Simple Regression Model I","heading":"9 Lecture 4: The Simple Regression Model I","text":"","code":""},{"path":"lecture-4-the-simple-regression-model-i.html","id":"slides-3","chapter":"9 Lecture 4: The Simple Regression Model I","heading":"Slides","text":"5 Simple Regression Model (link)","code":""},{"path":"lecture-4-the-simple-regression-model-i.html","id":"introduction-3","chapter":"9 Lecture 4: The Simple Regression Model I","heading":"9.1 Introduction","text":"previous lecture, explored can understand causal inference importance random assignment. Experiments allow us randomize treatment create believable counterfactuals. solely rely experiments estimate causal relations. Thus, study regression…\nlecture slide displayed full :\nFigure 9.1: Slides 4 Simple Regression Model .\n","code":""},{"path":"tutorial-4-the-simple-regression-model-i.html","id":"tutorial-4-the-simple-regression-model-i","chapter":"10 Tutorial 4: The Simple Regression Model I","heading":"10 Tutorial 4: The Simple Regression Model I","text":"","code":""},{"path":"tutorial-4-the-simple-regression-model-i.html","id":"what-is-this-tutorial-about-2","chapter":"10 Tutorial 4: The Simple Regression Model I","heading":"What is this tutorial about?","text":"can access tutorial clicking . tutorial test understanding Simple Regression Model (SRM), building concepts Wooldridge’s Introductory Econometrics Huntington-Klein’s Effect. ’ll engage theoretical foundations practical applications simple regression analysis related measures relationship variables.","code":""},{"path":"lecture-4-exercises.html","id":"lecture-4-exercises","chapter":"11 Lecture 4 Exercises","heading":"11 Lecture 4 Exercises","text":"tutorial created John Santos (minor adaptations ).","code":""},{"path":"lecture-4-exercises.html","id":"practice-exercises","chapter":"11 Lecture 4 Exercises","heading":"11.1 Practice exercises","text":"lecture:Using “fertil2” dataset “wooldridge” women living Republic Botswana 1988,produce scatterplot number children (children) y axis education (educ) x axis;two variables appear related?;estimate regression equation number children education (note: say regress y x);interpret \\(\\hat{\\beta_0}\\) \\(\\hat{\\beta_1}\\) ;plot regression line scatterplot;calculate \\(SST\\), \\(SSE\\) \\(SSR\\). Verify \\(SST = SSE + SSR\\);using \\(SST\\) , \\(SSE\\) \\(SSR\\), calculate R 2 regression. Verify R 2 reported summary regression output;interpret \\(R^2\\) regression.tutorial:Using sample 2019 CES dataset provided John, look feeling thermometer ratings Justin Trudeau (feel_trudeau) vary individual’s support free market principles (marketlib).Produce scatterplot two variables regression line visualized;Describe relationship (.e. positive negative);Run regression report coefficients mean;Calculate predicted rating Justin Trudeau following levels market liberalism: lower tertile (33rd percentile), mean, upper quartile (75 percentile), maximum;Explain well market liberalism explains someone rates Justin Trudeau; andExplain might u term model.","code":""},{"path":"lecture-4-exercises.html","id":"writing-math-in-rstudio","chapter":"11 Lecture 4 Exercises","heading":"11.2 Writing math in RStudio","text":"write math RStudio enclosing equations within dollar signs ($).\\(y = mx + b\\)can centre equation new line enclosing within two dollar signs.\\[y = mx + b\\]Subscript denoted underscore (_) superscript caret (^).\\[y = B_0 + B_1x_1 + u\\]Special symbols (greek letters, hats, etc.) prefaced backslash (\\) sometimes enclosed curly braces ({}).\\[ y = \\beta_0 + \\beta_1x_1 + u\\]\\[ \\hat{y} = \\hat{\\beta_0} + \\hat{\\beta}_1x_1\\]","code":""},{"path":"lecture-4-exercises.html","id":"stop-2","chapter":"11 Lecture 4 Exercises","heading":"11.3 STOP!!","text":"continue, try solving exercises . ’s way learn. , come back page see well .","code":""},{"path":"lecture-4-exercises.html","id":"continue-2","chapter":"11 Lecture 4 Exercises","heading":"11.4 Continue","text":"","code":""},{"path":"lecture-4-exercises.html","id":"lecture-exercises-solutions","chapter":"11 Lecture 4 Exercises","heading":"11.5 Lecture exercises (Solutions)","text":"","code":"\nlibrary(wooldridge)\ndata('fertil2')"},{"path":"lecture-4-exercises.html","id":"q1.-produce-a-scatterplot-with-number-of-children-children-on-the-y-axis-and-education-educ-on-the-x-axis","chapter":"11 Lecture 4 Exercises","heading":"11.5.1 Q1. Produce a scatterplot with number of children (children) on the y axis and education (educ) on the \\(x\\) axis","text":", use ggplot2 make scatterplot. also use Base R graphics, find ggplot2 easier (especially ’s party tidyverse follows conventions).Note, ggplot2, can command ggplot() command span several lines, connected using + sign. makes facilitates building graph layer--layer, easier, readable, easier troubleshoot.add random noise (.k.. jitter), include argument position = \"jitter\" within geom_point() function call.","code":"\nlibrary(ggplot2)\nggplot(fertil2) +\n  aes(x = educ, y = children) +\n  geom_point() + \n  labs(x = \"Education (years)\", \n       y = \"Number of children\",\n       title = \"Number of children by years of education\")\nggplot(fertil2) +\n  aes(x = educ, y = children) +\n  geom_point(position = \"jitter\") + \n  labs(x = \"Education (years)\", \n       y = \"Number of children\",\n       title = \"Number of children by years of education (with jitter)\")"},{"path":"lecture-4-exercises.html","id":"q2.-how-do-the-two-variables-appear-to-be-related","chapter":"11 Lecture 4 Exercises","heading":"11.5.2 Q2. How do the two variables appear to be related?;","text":"appears negative relationship amount education number children. number years school attended increases, number children women tends decrease.","code":""},{"path":"lecture-4-exercises.html","id":"q3.-estimate-the-regression-equation-of-the-number-of-children-on-education-note-we-say-to-regress-y-on-x","chapter":"11 Lecture 4 Exercises","heading":"11.5.3 Q3. Estimate the regression equation of the number of children on education (note: we say “to regress \\(y\\) on \\(x\\)”);","text":"Remember, equation population model :\\[children = \\beta_0 + \\beta_1educ + \\mu \\]regression equation :\\[\\hat{children} = 3.496 - .210educ\\]\\[n = 4361, R^2 = 0.137\\]","code":"\nlibrary(dplyr)\ndat <- fertil2 %>%\n  select(c(children, educ)) %>%\n  na.omit()## select: dropped 25 variables (mnthborn, yearborn, age, electric, radio, …)\nmodel1 <- lm(children ~ educ, data = dat)\nsummary(model1)## \n## Call:\n## lm(formula = children ~ educ, data = dat)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -3.495 -1.496 -0.399  1.182  9.505 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  3.49554    0.05612   62.28   <2e-16 ***\n## educ        -0.20965    0.00796  -26.34   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 2.064 on 4359 degrees of freedom\n## Multiple R-squared:  0.1373, Adjusted R-squared:  0.1371 \n## F-statistic: 693.7 on 1 and 4359 DF,  p-value: < 2.2e-16"},{"path":"lecture-4-exercises.html","id":"q4.-interpret-hatbeta_0-and-hatbeta_1","chapter":"11 Lecture 4 Exercises","heading":"11.5.4 Q4. Interpret \\(\\hat{\\beta_0}\\) and \\(\\hat{\\beta_1}\\);","text":"\\(\\hat{\\beta_0} = 3.5\\). intercept (constant), value \\(\\hat{y}\\) coefficients equal 0. means woman education predicted 3.5 children.\\(\\hat{\\beta_1} = -0.2\\). coefficient educ. means , average, every additional year schooling women , predict 0.2 fewer children.","code":""},{"path":"lecture-4-exercises.html","id":"q5.-plot-the-regression-line-on-the-scatterplot","chapter":"11 Lecture 4 Exercises","heading":"11.5.5 Q5. Plot the regression line on the scatterplot;","text":"ways . First, generate predictions, save data set, plot .Running lm() function automatically calculates predictions (also know fitted values y-hats), can just extract model object. stored slot $fitted.values., take fitted values store new column called “yhat.”Another way retrieve fitted values command fitted.values(). produces exactly results $fitted.values, can seen .plot just fitted values x-axis, ’d get graph looks like :predict() function. function used calculate predicted values, given combination values input \\(x\\)’s model.Theoretically, use get y-hats specifying new values. However, mechanics function works, doesn’t produce exactly values using $fitted.values fitted.values() (though comes close).also calculate predictions manually using coefficients. practice, wouldn’t actually ; just show math R behind--scenes.Finally, avoid make calculations entering numbers manually (.e. retrieving model object). put rounding numbers end, lest throw subsequent calculations.example, numbers aren’t different (see 4th column ). , doesn’t mean ’ll always able get away .Regardless calculate predictions, can add original ggplot() statement geom_line().simple (bivariate) regression, simplest way add regression line make use command geom_smooth(), built ggplot2.example, ’ve also added addition geom_point() command aesthetics mapped mean values predictor response variables. show point coordinates \\([\\bar{educ},\\bar{children}]\\) (.e. \\([5.9, 2.3]\\) always regression line.","code":"\ndat$yhat <- model1$fitted.values\ndat$yhat2 <- fitted.values(model1)\ndat$yhat[1:10] == dat$yhat2[1:10]##  [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\nlibrary(ggplot2)\nggplot(dat) +\n  aes(x = educ, y = yhat) +\n  geom_point() + \n  labs(x = \"Education (years)\", \n       y = \"Predicted number of children\",\n       title = \"Predicted number of children by years of education\")\ndat$yhat3 <- predict(model1)\ndat$yhat[1:10] == dat$yhat3[1:10]##  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\ndat$calcpreds <- model1$coefficients[[1]] + (model1$coefficients[[2]] * dat$educ)\ntibble(\n  \"fitted.values()\" = dat$yhat,\n  \"predict()\" = dat$yhat3,\n  \"Manual calculation\" = dat$calcpreds) %>% \n  head()## # A tibble: 6 × 3\n##   `fitted.values()` `predict()` `Manual calculation`\n##               <dbl>       <dbl>                <dbl>\n## 1             0.980       0.980                0.980\n## 2             0.770       0.770                0.770\n## 3             2.45        2.45                 2.45 \n## 4             2.66        2.66                 2.66 \n## 5             1.19        1.19                 1.19 \n## 6             2.03        2.03                 2.03\ndat$roundpreds <- 3.496 + (-0.210 * dat$educ)\ntibble(\n  \"fitted.values()\" = dat$yhat,\n  \"predict()\" = dat$yhat3,\n  \"Manual calculation\" = dat$calcpreds,\n  \"Rounded calculation\" = dat$roundpreds) %>% \n  head()## # A tibble: 6 × 4\n##   `fitted.values()` `predict()` `Manual calculation` `Rounded calculation`\n##               <dbl>       <dbl>                <dbl>                 <dbl>\n## 1             0.980       0.980                0.980                 0.976\n## 2             0.770       0.770                0.770                 0.766\n## 3             2.45        2.45                 2.45                  2.45 \n## 4             2.66        2.66                 2.66                  2.66 \n## 5             1.19        1.19                 1.19                  1.19 \n## 6             2.03        2.03                 2.03                  2.03\nggplot(dat) +\n  geom_point(aes(x = educ, y = children), position = \"jitter\") + \n  geom_line(aes(x = educ, y = yhat), color = \"red\", linewidth = 1) +\n  labs(x = \"Education (years)\", \n       y = \"Number of children\",\n       title = \"Number of children by years of education\")\nggplot(dat, aes(x = educ, y = children)) +\n  geom_point(position = \"jitter\") + \n  geom_smooth(method = \"lm\", fullrange = FALSE) +\n  labs(x = \"Education (years)\", \n       y = \"Number of children\",\n       title = \"Number of children by years of education\") +\n  geom_point(aes(x = mean(dat$educ), y = mean(dat$children)), color = \"red\", size = 4)## `geom_smooth()` using formula = 'y ~ x'"},{"path":"lecture-4-exercises.html","id":"q6.-calculate-sst-sse-and-ssr.-verify-that-sst-sse-ssr","chapter":"11 Lecture 4 Exercises","heading":"11.5.6 Q6. Calculate SST, SSE and SSR. Verify that \\(SST = SSE + SSR\\);","text":"First, ’ll generate predictions.Calculate \\(SST\\) (sum squares TOTAL).formula, words, interpreted , total sum squares equal sum squared differences observed Y average Y.\\[SST = \\Sigma{ ^n_{=1} ( y_i - \\bar{y} )^2 }\\]Calculate \\(SSE\\) (sum squares EXPLAINED).words, formula interpreted , explained sum squares equal sum squared differences predicted Y average Y.\\[SSE = \\Sigma{ ^n_{=1} ( \\hat{y}_i - \\bar{y} )^2 }\\]Calculate \\(SSR\\) (sum squares RESIDUAL).\\[SST = \\Sigma{ ^n_{=1} \\hat{u_i}^2 }\\]model’s residuals stored slot $residuals, can use inputs calculation. can also retrieve using resid() function.manual calculations mostly pedagogical purposes. practice, pre-built functions calculate quantities us.can use anova() function display ANOVA table regression, shows various sum--squares statistics.Note total sum squares reported ANOVA table, easily calculated.","code":"\ndat$childrenhat <- model1$fitted.values\nmodel1_sst <- sum( (dat$children - mean(dat$children)) ^ 2 )\nmodel1_sst## [1] 21527.18\nmodel1_sse <- sum( (dat$yhat - mean(dat$children)) ^ 2 )\nmodel1_sse## [1] 2955.401\nmodel1_ssr <- model1_sst - model1_sse\nmodel1_ssr## [1] 18571.78\nsum(model1$residuals^2)## [1] 18571.78\nsum(resid(model1)^2)## [1] 18571.78\nanova(model1)## Analysis of Variance Table\n## \n## Response: children\n##             Df  Sum Sq Mean Sq F value    Pr(>F)    \n## educ         1  2955.4 2955.40  693.67 < 2.2e-16 ***\n## Residuals 4359 18571.8    4.26                      \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nanova(model1)[1,2] + anova(model1)[2,2]## [1] 21527.18"},{"path":"lecture-4-exercises.html","id":"q7.-using-sst-sse-and-ssr-calculate-the-r2-of-the-regression.-verify-it-is-the-same-as-the-r2-reported-in-the-summary-of-your-regression-output","chapter":"11 Lecture 4 Exercises","heading":"11.5.7 Q7. Using \\(SST\\), \\(SSE\\) and \\(SSR\\), calculate the \\(R^2\\) of the regression. Verify it is the same as the \\(R^2\\) reported in the summary of your regression output;","text":"proportion variance Y explained X simple ratio \\(SSE/SST\\).can check model reports…Note residual standard error 2.064 4359 degrees freedom. equal standard deviation residuals (\\({\\sqrt{\\hat{\\sigma^2}}}\\)) (makes sense use model’s SDs approximations population’s SEs).","code":"\nmodel1_sse / model1_sst## [1] 0.137287\nsummary(model1)## \n## Call:\n## lm(formula = children ~ educ, data = dat)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -3.495 -1.496 -0.399  1.182  9.505 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  3.49554    0.05612   62.28   <2e-16 ***\n## educ        -0.20965    0.00796  -26.34   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 2.064 on 4359 degrees of freedom\n## Multiple R-squared:  0.1373, Adjusted R-squared:  0.1371 \n## F-statistic: 693.7 on 1 and 4359 DF,  p-value: < 2.2e-16\nsd(model1$residuals)## [1] 2.063875"},{"path":"lecture-4-exercises.html","id":"q8.-interpret-the-r2-of-the-regression.","chapter":"11 Lecture 4 Exercises","heading":"11.5.8 Q8. Interpret the R^2 of the regression.","text":"\\(R^2 = 0.137\\). means education explains 14% variation number children.","code":""},{"path":"lecture-4-exercises.html","id":"additional-practice-exercises","chapter":"11 Lecture 4 Exercises","heading":"11.6 Additional practice exercises","text":"Using 2019 CES dataset, look feeling thermometer ratings Justin Trudeau (feel_trudeau) vary individual’s support free market principles (marketlib).analysis…Produce scatterplot two variables regression line visualized;Describe relationship (.e. positive negative);Run regression report coefficients mean;Calculate predicted rating Justin Trudeau following levels market liberalism: lower tertile (33rd percentile), mean, upper quartile (75 percentile), maximum;Explain well market liberalism explains someone rates Justin Trudeau; andExplain might \\(\\mu\\) term model.","code":""},{"path":"lecture-4-exercises.html","id":"stop-3","chapter":"11 Lecture 4 Exercises","heading":"11.7 STOP!!","text":"continue, try solving exercises . ’s way learn. , come back page see well .","code":""},{"path":"lecture-4-exercises.html","id":"continue-3","chapter":"11 Lecture 4 Exercises","heading":"11.8 Continue","text":"answer questions, ’m going start looking summary statistics variables.average, Canadians rate Trudeau 45 points 100 feeling thermometer scale (SD = 34.5), score 8.6 market liberalism scale (SD = 3.5), ranges 0 16.","code":"\nlibrary(dplyr)\nlibrary(ggplot2)\nload(\"Sample_data/ces.rda\")\nsummary(ces$feel_trudeau)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##    0.00    7.00   50.00   44.85   75.00  100.00    2409\nsd(ces$feel_trudeau, na.rm = TRUE)## [1] 34.54668\nsummary(ces$marketlib)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##    0.00    6.00    9.00    8.59   11.00   16.00   32684\nsd(ces$marketlib, na.rm = TRUE)## [1] 3.519915"},{"path":"lecture-4-exercises.html","id":"q1.-produce-a-scatterplot-of-the-two-variables-with-a-regression-line-visualized","chapter":"11 Lecture 4 Exercises","heading":"11.8.1 Q1. Produce a scatterplot of the two variables with a regression line visualized","text":"","code":"\nggplot(ces, aes(x = marketlib, y = feel_trudeau)) +\n  geom_point(position = \"jitter\") + \n  geom_smooth(method = \"lm\") +\n  labs(x = \"Market liberalism\", \n       y = \"Feeling thermometer ratings of Trudeau\",\n       title = \"Trudeau ratings by market liberalism\") +\n  theme_minimal()## `geom_smooth()` using formula = 'y ~ x'"},{"path":"lecture-4-exercises.html","id":"q2.-describe-the-relationship-i.e.-is-it-positive-or-negative","chapter":"11 Lecture 4 Exercises","heading":"11.8.2 Q2. Describe the relationship (i.e. is it positive or negative)","text":"appears negative relationship market liberalism ratings Trudeau–.e. support free market principles increases, positive feelings towards Trudeau decrease.can difficult see without regression line variables upper lower bounds (.e. go onto infinity).situations, look diagonal pairs corners denser opposite diagonal. , top left bottom right corners denser bottom left top right corners.","code":""},{"path":"lecture-4-exercises.html","id":"q3.-run-the-regression-and-report-the-coefficients-and-what-they-mean","chapter":"11 Lecture 4 Exercises","heading":"11.8.3 Q3. Run the regression and report the coefficients and what they mean","text":"Regressing feel_trudeau marketlib gives us following regression equation:\\[\\hat{feel\\_trudeau} = 68.399 + -2.852marketlib\\]\n\\[n = 4797, R^2 = 0.085\\]results indicate , every one-point increase market liberalism (scale 0 16), rating Trudeau decreases, average, 2.9 points. Moving halfway (8 points) across scale (e.g. difference far left centre centre far right) result shift 23 points average (2.9 * 8 = 23.2).intercept tells us average rating Justin Trudeau market liberalism 0 (.e. left-position) 68.399.","code":"\njtmod <- lm(feel_trudeau ~ marketlib, data = ces)\nsummary(jtmod)## \n## Call:\n## lm(formula = feel_trudeau ~ marketlib, data = ces)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -68.399 -31.323   0.121  28.677  74.382 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  68.3989     1.2546   54.52   <2e-16 ***\n## marketlib    -2.8520     0.1352  -21.10   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 33.11 on 4795 degrees of freedom\n##   (32936 observations deleted due to missingness)\n## Multiple R-squared:  0.08496,    Adjusted R-squared:  0.08477 \n## F-statistic: 445.2 on 1 and 4795 DF,  p-value: < 2.2e-16"},{"path":"lecture-4-exercises.html","id":"q4.-calculate-the-predicted-rating-for-justin-trudeau-at-the-following-levels-of-market-liberalism-the-lower-tertile-33rd-percentile-the-mean-the-upper-quartile-75-percentile-and-the-maximum","chapter":"11 Lecture 4 Exercises","heading":"11.8.4 Q4. Calculate the predicted rating for Justin Trudeau at the following levels of market liberalism: the lower tertile (33rd percentile), the mean, the upper quartile (75 percentile), and the maximum","text":"First, let’s find ratings Trudeau quantiles interest.quantile() function gives us values 0th (min), 25th (lower quartile), 50th (.e. median), 75th (upper quartile), 100th (max) percentiles. Note, data set missing values, use option na.rm = TRUE, otherwise function work.can specify specific value quantile() function return get 33rd 75th percentile.ways can calculate predicted probabilities.First, math manually plug value market liberalism regression equation. Let’s 33rd percentile market liberalism (\\(marketlib=7\\)).avoid rounding errors, ’s better use actual coefficients returned model, can retrieve using coefs() $coefficients. ’s looks like example .Finally, can also use predict() function specify values coefficient using argument newdata=. ’s example format.Let’s continue using predict() function calculate predicted values marketlib mean (8.59)., predict feel_trudeau marketlib 75th percentile.predict() max value marketlib.","code":"\nquantile(ces$marketlib, na.rm = TRUE)##   0%  25%  50%  75% 100% \n##    0    6    9   11   16\ntibble(\n  \"qtile33\" = quantile(ces$marketlib, .33, na.rm = TRUE),\n  \"mean\" = mean(ces$marketlib, na.rm = TRUE),\n  \"qtile75\" = quantile(ces$marketlib, .75, na.rm = TRUE),\n  \"max\" = max(ces$marketlib, na.rm = TRUE))## # A tibble: 1 × 4\n##   qtile33  mean qtile75   max\n##     <dbl> <dbl>   <dbl> <dbl>\n## 1       7  8.59      11    16\n68.399 + (-2.852 * 7)## [1] 48.435\njtmod$coefficients[[1]] + \n  (jtmod$coefficients[[2]] *  quantile(ces$marketlib, .33, na.rm = TRUE))##      33% \n## 48.43472\npredict(jtmod, \n        newdata = data.frame(\n          marketlib = quantile(ces$marketlib, .33, na.rm = TRUE)\n          )\n        ) %>% \n  unname()## [1] 48.43472\npredict(jtmod, \n        newdata = data.frame(marketlib = mean(ces$marketlib, na.rm = TRUE))) %>% \n  unname()## [1] 43.91406\npredict(jtmod, \n        newdata = data.frame((marketlib = quantile(ces$marketlib, .75, na.rm = TRUE)))) %>% \n  unname()## [1] 37.0266\npredict(jtmod, \n        newdata = data.frame((marketlib = max(ces$marketlib, na.rm = TRUE)))) %>% \n  unname()## [1] 22.76645"},{"path":"lecture-4-exercises.html","id":"q5.-explain-how-well-market-liberalism-explains-ratings-of-justin-trudeau","chapter":"11 Lecture 4 Exercises","heading":"11.8.5 Q5. Explain how well market liberalism explains ratings of Justin Trudeau","text":"simple regression model, \\(R^2=0.085\\). means market liberalism explains 8.5% variation feeling thermometer ratings Justin Trudeau. Another way think knowing someone’s score market liberalism scale improves ability predict 8.5% guess based knowing average market liberalism Canadians whole.doesn’t seem surprising, given expect self-reported ideology relationship ratings party leader, many factors.","code":""},{"path":"lecture-4-exercises.html","id":"q6.-explain-what-might-be-in-the-u-term-of-the-model","chapter":"11 Lecture 4 Exercises","heading":"11.8.6 Q6. Explain what might be in the u term of the model","text":"Obviously, many things besides market liberalism go someone rates Justin Trudeau. factors likely correlated market liberalism ratings Justin Trudeau—, , likely source omitted variable bias—include one’s stand social moral issues (often called moral traditionalism), one’s party identification, evaluations economic conditions, personal characteristics (often called “socio-demographics”).","code":""},{"path":"lecture-4-exercises.html","id":"bonus-content","chapter":"11 Lecture 4 Exercises","heading":"11.9 Bonus content","text":"","code":""},{"path":"lecture-4-exercises.html","id":"looking-inside-model-objects","chapter":"11 Lecture 4 Exercises","heading":"11.9.1 Looking inside model objects…","text":"Model objects created lm() list contain various quantities interest. Let’s take look inside. can using command View(model1) (note capital “V” “View”).can also look names item model1 object using command names(model1).Notice can see coefficients, ’re missing things like standard errors, t-statistics, p-values. ’s actually relatively easy calculate math variance-covariance matrix, ’re point yet.easiest way get quantities getting model summary table.’re used printing using summary() command. However, can also assign output command object, get values want item $coefficients.Note, assign mysummary$coefficients object, ’ll find ’s actually array numbers, makes bit tricky extract ’s contents.can get around telling R treat object like ’s data frame using .data.frame() command.Now can work like data frames extract columns using $ operator.Note, space special characters columns, need use backticks (.e. ` character, “lower-case tilde”) around variable names.","code":"\n# View(model1)\nnames(model1)##  [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"          \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"   \"xlevels\"      \n## [10] \"call\"          \"terms\"         \"model\"\nmysummary <- summary(model1)\nnames(mysummary)##  [1] \"call\"          \"terms\"         \"residuals\"     \"coefficients\"  \"aliased\"       \"sigma\"         \"df\"            \"r.squared\"     \"adj.r.squared\"\n## [10] \"fstatistic\"    \"cov.unscaled\"\nmysummary$coefficients##               Estimate  Std. Error   t value      Pr(>|t|)\n## (Intercept)  3.4955406 0.056123844  62.28263  0.000000e+00\n## educ        -0.2096504 0.007960142 -26.33752 5.413817e-142\nmycoefs <- mysummary$coefficients\nmycoefs##               Estimate  Std. Error   t value      Pr(>|t|)\n## (Intercept)  3.4955406 0.056123844  62.28263  0.000000e+00\n## educ        -0.2096504 0.007960142 -26.33752 5.413817e-142\nclass(mycoefs)## [1] \"matrix\" \"array\"\nmycoefs1 <- as.data.frame(mysummary$coefficients)\nclass(mycoefs1)## [1] \"data.frame\"\nmycoefs1##               Estimate  Std. Error   t value      Pr(>|t|)\n## (Intercept)  3.4955406 0.056123844  62.28263  0.000000e+00\n## educ        -0.2096504 0.007960142 -26.33752 5.413817e-142\nmycoefs1$Estimate## [1]  3.4955406 -0.2096504\nmycoefs1$`Std. Error`## [1] 0.056123844 0.007960142"},{"path":"lecture-4-exercises.html","id":"how-se-t-and-p-are-calculated","chapter":"11 Lecture 4 Exercises","heading":"11.9.2 How SE, t, and p are calculated","text":"’re curious calculate Standard Errors, t-values, p-values coefficients, chunk shows equations.SEs square root diagonal variance-covariance matrix (won’t know course).t-values (t-statistics) quotients coefficients divided SEs (.e. \\(\\frac{b_i}{SE_i}\\)).p-values integrals t-distribution evaluated absolute values t-values, given residual degrees freedom model (course, ’ll using statistical table, knowing R comes handy).","code":"\ndata.frame(\n  b = model1$coefficients,\n  se = sqrt(diag(vcov(model1))),\n  t = model1$coefficients / sqrt(diag(vcov(model1))),\n  p = 2 * pt(abs(model1$coefficients / sqrt(diag(vcov(model1)))), \n             model1$df.residual, lower.tail = FALSE))##                      b          se         t             p\n## (Intercept)  3.4955406 0.056123844  62.28263  0.000000e+00\n## educ        -0.2096504 0.007960142 -26.33752 5.413817e-142"}]
