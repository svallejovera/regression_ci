[{"path":"index.html","id":"regressions-and-causal-inference","chapter":"“Regressions and Causal Inference”","heading":"“Regressions and Causal Inference”","text":" Welcome site course PS9591: “Regressions Causal Inference” Western University, taught Sebastián Vallejo Vera. week, find lecture slides, lecture code, lab exercises, lab code corresponding topic.class divided lectures tutorials. go lectures tutorials simultaneously. Thus, arranged website way shows suggested order lecture tutorials carried .start, don’t forget read Syllabus check Perusall readings course. site corrected/updated throughout semester(s).","code":""},{"path":"index.html","id":"about-tutorials","chapter":"“Regressions and Causal Inference”","heading":"0.1 About Tutorials","text":"tutorials interactive R documents can also run computer. allows practice concepts experiment different approaches pace. ’s get started.","code":""},{"path":"index.html","id":"prerequisites","chapter":"“Regressions and Causal Inference”","heading":"0.1.1 Prerequisites","text":"running tutorials, make sure :R installed computer (version 4.0.0 higher)RStudio installed (recent version)following R packages installed. can install running commands R:","code":"\n# Install required packages\ninstall.packages(\"learnr\")\ninstall.packages(\"wooldridge\")\ninstall.packages(\"tidyverse\")\ninstall.packages(\"tidylog\")\ninstall.packages(sjPlot) # to plot some models\ninstall.packages(readstata13) # to load .dta files"},{"path":"index.html","id":"running-a-tutorial","chapter":"“Regressions and Causal Inference”","heading":"0.1.2 Running a Tutorial","text":"two ways run tutorial locally:","code":""},{"path":"index.html","id":"method-1-using-rstudio","chapter":"“Regressions and Causal Inference”","heading":"0.1.2.1 Method 1: Using RStudio","text":"Download tutorial file (.Rmd extension)Open RStudioClick “Run Document” button top editorThe tutorial open new window","code":""},{"path":"index.html","id":"method-2-using-r-console","chapter":"“Regressions and Causal Inference”","heading":"0.1.2.2 Method 2: Using R Console","text":"tutorial file working directory, can run:Replace “filename” name tutorial file (without .Rmd extension).","code":"\nrmarkdown::run_tutorial(\"filename\", package = \"learnr\")"},{"path":"index.html","id":"tips-for-success","chapter":"“Regressions and Causal Inference”","heading":"0.1.3 Tips for Success","text":"working tutorials locally:Make sure required packages loaded tutorial’s setup chunkIf modify tutorial code, save file runningTo clear tutorial cache start fresh, just click “Start ” button bottom left corner.","code":""},{"path":"index.html","id":"troubleshooting-common-issues","chapter":"“Regressions and Causal Inference”","heading":"0.1.4 Troubleshooting Common Issues","text":"encounter problems:Tutorial won’t knit: Check required packages installedExercise chunks don’t run: Verify learnr properly loadedPrevious answers persist: Clear cache using code provided abovePackage found: Run install.packages() missing package","code":""},{"path":"index.html","id":"getting-help","chapter":"“Regressions and Causal Inference”","heading":"0.1.5 Getting Help","text":"need assistance:Check tutorial error messages specific package requirementsReview setup chunk missing dependenciesConsult learnr documentationAsk questions office hours send e-mailAsk ChatGPT (?)","code":""},{"path":"index.html","id":"next-steps","chapter":"“Regressions and Causal Inference”","heading":"0.1.6 Next Steps","text":"getting tutorials running locally, can:Experiment modifying codeCreate practice exercisesTry different approaches analysis tasksSave work future referenceRemember tutorials learning tools. Feel free experiment try different approaches – ’s learn best!","code":""},{"path":"index.html","id":"assignments","chapter":"“Regressions and Causal Inference”","heading":"0.2 Assignments","text":"list assignments course. assignments must handed pdf documents using R Markdown.","code":""},{"path":"index.html","id":"final-exam","chapter":"“Regressions and Causal Inference”","heading":"0.3 Final Exam","text":"final exam require students replicate findings papers, interpret results. Final Exam, post required datasets replication exercise :COMING SOON…","code":""},{"path":"index.html","id":"acknowledgments","chapter":"“Regressions and Causal Inference”","heading":"0.4 Acknowledgments","text":"organization course based great textbook ‘Effect: Introduction Research Design Causality’ Nick Huntington-Klein, freely available . code used throughout main lectures patchwork code, code borrows heavily internet (’s true code). try best give credit original authors code (possible). code labs created revised two amazing doctoral students1 Western University, Hugo Machado John Santos (posted permission).","code":""},{"path":"lecture-1-what-is-causal-inference.html","id":"lecture-1-what-is-causal-inference","chapter":"1 Lecture 1: What is Causal Inference?","heading":"1 Lecture 1: What is Causal Inference?","text":"","code":""},{"path":"lecture-1-what-is-causal-inference.html","id":"slides","chapter":"1 Lecture 1: What is Causal Inference?","heading":"Slides","text":"2 Causal Inference? (link)","code":""},{"path":"lecture-1-what-is-causal-inference.html","id":"introduction","chapter":"1 Lecture 1: What is Causal Inference?","heading":"1.1 Introduction","text":"first week, introduce ‘causal inference’ concept interest, main problems determining causality observational data. fancy code week.lecture slide displayed full :\nFigure 1.1: Slides 2 Causal Inference?.\n","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","text":"tutorial created Hugo Machado John Santos (minor adaptations ).tutorial guide setting R RStudio, installing essential packages, learning basics RMarkdown, suggesting best practices help keep work organized find solutions common problems (definitely encounter).","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"installing-r-and-rstudio","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.1 Installing R and RStudio","text":"R programming language ’ll using course. optimized statistics data analysis. Additionally, open source, easily customizable, popular academia, gives edge proprietary (e.g., Stata, SPSS) general purpose frameworks (e.g., Python) best language learn social scientists working data.Go R Project website: https://mirror.csclub.uwaterloo.ca/CRAN/Go R Project website: https://mirror.csclub.uwaterloo.ca/CRAN/link send CRAN mirror hosted University Waterloo.link send CRAN mirror hosted University Waterloo.Select appropriate link operating system (Windows, macOS, Linux).Select appropriate link operating system (Windows, macOS, Linux).Follow instructions download install R.\nmacOS users:\nMac Apple Silicon chip (M1, M2, M3, etc.), choose arm64 version.\nMac Intel chip, choose x86_64 version.\n\nNote: updating R, ’ll need reinstall packages. ’s good idea time right deadline.\nFollow instructions download install R.macOS users:\nMac Apple Silicon chip (M1, M2, M3, etc.), choose arm64 version.\nMac Intel chip, choose x86_64 version.\nmacOS users:Mac Apple Silicon chip (M1, M2, M3, etc.), choose arm64 version.Mac Intel chip, choose x86_64 version.Note: updating R, ’ll need reinstall packages. ’s good idea time right deadline.Note: updating R, ’ll need reinstall packages. ’s good idea time right deadline.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"rstudio","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.1.1 RStudio","text":"RStudio Integrated Development Environment (IDE) makes working R much easier user-friendly.Go RStudio Desktop download page: https://posit.co/download/rstudio-desktop/Download free version RStudio Desktop operating system.Follow instructions install RStudio.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"a-quick-tour-of-the-rstudio-interface","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.2 A Quick Tour of the RStudio Interface","text":"open RStudio, ’ll see four main panes:Source (top-left): write edit R code RMarkdown documents.Console (bottom-left): can run R code interactively see output.Environment/History (top-right): Environment tab shows objects (data, variables, functions) created. History tab shows commands run.Files/Plots/Packages/Help (bottom-right): pane several tabs:\nFiles: Allows browse manage files computer.\nPlots: Displays plots create.\nPackages: Shows installed R packages allows load/unload .\nHelp: Displays R documentation.\nFiles: Allows browse manage files computer.Plots: Displays plots create.Packages: Shows installed R packages allows load/unload .Help: Displays R documentation.can customize layout panes Tools > Global Options > Pane Layout.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"r-working-directory","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.3 R Working Directory","text":"working directory folder R look files save output default. Issues conflicting working directories common, especially multiple folders different projects. best practices deal .Using setwd(): can use setwd() function set working directory. example, setwd(\"~/Documents/R Projects/MyProject\") sets working directory “MyProject” folder within “R Projects” folder “Documents” directory. can also open new script (tab top left), right-click tab, tell R “Set working directory” wherever script located. working external data files (e.g., .dta database, example), data need folder script working .Using RStudio Interface: can also set working directory RStudio menu: “Session” > “Set Working Directory” > “Choose Directory…”.R Projects: better organization, consider creating R Projects assignments. R Project special type working directory makes easier manage code, data, output. can create new project going “File” > “New Project…”. RStudio automatically set working directory project folder. information working projects, consult guide: https://support.posit.co/hc/en-us/articles/200526207-Using-RStudio-Projects","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"introduction-to-rmarkdown","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.4 Introduction to RMarkdown","text":"RMarkdown file format allows combine R code, output (e.g., tables, plots), text single document. ’s powerful tool creating reproducible reports assignments. can also use write HTML render PDFs. However, can little finicky intuitive write , compared common word processors like MSWord Google Docs, takes practice (patience) get place feel comfortable writing .","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"why-use-rmarkdown","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.4.1 Why Use RMarkdown?","text":"Reproducibility: code, output, text one place, making easy reproduce analysis.Clarity: can interweave code explanations narrative, making work easier understand.Efficiency: can generate different output formats (HTML, PDF, Word) RMarkdown file. outputs also look pretty nice.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"basic-rmarkdown-syntax","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.4.2 Basic RMarkdown Syntax","text":"Code Chunks: R code enclosed “chunks” start ```{r} end ```.\n\n# R code chunk\nx <- 10\ny <- 20\nx + yCode Chunks: R code enclosed “chunks” start ```{r} end ```.Headers: can create headers using #, ##, ###, etc. number # determines level header.Headers: can create headers using #, ##, ###, etc. number # determines level header.Text Formatting: can format text using Markdown syntax. example:\nItalic: *italic*\nBold: **bold**\nCode: `code`\nLinks: [Link Text](URL)\nText Formatting: can format text using Markdown syntax. example:Italic: *italic*Bold: **bold**Code: `code`Links: [Link Text](URL)","code":"\n# This is an R code chunk\nx <- 10\ny <- 20\nx + y"},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"creating-an-rmarkdown-file","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.4.3 Creating an RMarkdown File","text":"RStudio, go “File” > “New File” > “R Markdown…”.Choose title author name.Select desired output format (e.g., HTML, PDF).Click “OK”.RStudio create new RMarkdown file example content. can edit file, add code text, “knit” generate output document.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"knitting","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.4.4 Knitting","text":"“Knitting” process converting RMarkdown file output document. knit document, click “Knit” button top Source pane. can choose output format dropdown menu next “Knit” button.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"rmarkdown-cheatsheet","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.4.5 RMarkdown cheatsheet:","text":"useful quick guide can use help formatting related tasks: https://rstudio.github.io/cheatsheets/html/rmarkdown.html","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"installing-r-packages","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.5 Installing R Packages","text":"R packages extend functionality base R. progress course, ’ll use several packages help perform different tasks related statistical analysis. need install packages , need load new session.basic packages use go installing .Experienced: experience R, might interested exploring pacman package. provides convenient way manage packages, allowing load, install, update packages using single function, p_load(). example, instead repeated install.packages operations , pacman installed use one line like: pacman::p_load(devtools, remotes, foreign, readstata13, rio, labelled, sjlabelled, tidyverse, fixest, wooldridge, modelsummary, stargazer, ggplot2, knitr, kableExtra, markdown, car, carData, lmtest, sandwich, survey, srvyr). Using pacman may also automatically install packages CRAN, Bioconductor GitHub, according latest version . ’re interested, can learn pacman CRAN page. However, course, using standard install.packages() method sufficient.","code":"\n# Install packages for data import/export:\ninstall.packages(\"foreign\")\ninstall.packages(\"rio\")\n\n# Install tidyverse, a collection of packages for data science:\ninstall.packages(\"tidyverse\")\n\n# Install wooldridge, which contains datasets you will use for the assignments:\ninstall.packages(\"wooldridge\")\n\n# Install knitr and markdown for improved RMarkdown functionality:\ninstall.packages(\"knitr\")\ninstall.packages(\"markdown\")"},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"using-ai-tools-to-assist-with-r-programming","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.6 Using AI Tools to Assist with R Programming","text":"Large Language Models (LLMs) related AI tools, ChatGPT, Copilot Gemini, can valuable assistants learning using R. used correctly, can save lot time, especially debugging finding ways performing specific tasks ’re really familiar . However, ’s crucial use responsibly ethically. general tips using tools.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"how-ai-can-help","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.6.1 How AI Can Help","text":"Code Suggestions Auto-Completion: AI tools like GitHub Copilot can suggest code snippets type, helping write code faster fewer errors. also hallucinate times, mindful suggesting. ’m big fan auto-complete, ’s usually better either ask something specific ask edits base code ’ve already written.Debugging Assistance: encounter error, AI can help explain error message means suggest potential solutions. Just copy paste error message (relevant excerpt), tell wanted , ask causing error.Understanding Functions Packages: AI can provide explanations R functions work, arguments take, use effectively. Check documentation make sure LLMs telling something mark.Learning New Concepts: can ask AI explain statistical concepts R programming topics way ’s easy understand. Documentation references StackOverflow can bit cryptic.Finding Relevant Documentation: AI can help locate relevant documentation R packages functions.Generating Code Specific Tasks: can describe task want accomplish, AI can generate R code perform task. better informed prompt , better output get. models typically better contained, well-defined, tasks broad tasks underspecified.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"limitations-and-ethical-considerations","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.6.2 Limitations and Ethical Considerations","text":"Critical Thinking Essential: AI tool, replacement understanding. Always critically evaluate code generated AI. Make sure understand works using .Don’t Blindly Copy Paste: Avoid copying pasting code without understanding . can lead errors lack comprehension.Avoid Plagiarism: transparent use AI. Properly cite AI-generated code ideas assignments. instructors need know work came AI assistance.AI Makes Mistakes: AI perfect. can generate incorrect inefficient code. Always test code thoroughly.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"prompt-engineering-tips","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.6.3 Prompt Engineering Tips","text":"Specific Clear: specific prompts, better AI understand request.Provide Context: ’re asking specific piece code, include relevant code prompt.Break Complex Tasks: complex task, break smaller, manageable steps.Iterate Refine: AI doesn’t give answer ’re looking , try rephrasing prompt providing information.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"example","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.6.4 Example","text":"’s example use AI tool help generate plot:Prompt: “data frame called mydata columns x y. can create scatterplot y x using ggplot2, blue points red trend line?”AI-Generated Code (example):Remember: still need load ggplot2 package (library(ggplot2)) data frame mydata loaded R environment code work.","code":"\nggplot(mydata, aes(x = x, y = y)) +\n  geom_point(color = \"blue\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"red\")"},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"quick-example-importing-and-checking-data-from-wooldridge","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.7 Quick Example: Importing and Checking Data from wooldridge","text":"Let’s load dataset wooldridge package take quick look . ’ll use wage1 dataset, contains information wages individual characteristics.Explanation:library(wooldridge): Loads wooldridge package, making datasets available.data(\"wage1\"): Loads wage1 dataset R environment.head(wage1): Displays first six rows dataset, allowing see variable names sample data.\nExercise: Try changing number inside parentheses head() function display different number rows.\nExercise: Try changing number inside parentheses head() function display different number rows.summary(wage1): Provides descriptive statistics variable dataset (e.g., mean, median, min, max, quartiles).str(wage1): Shows structure dataset, including data type variable (e.g., numeric, integer, factor).","code":"\n# Load the wooldridge package\nlibrary(wooldridge)\n\n# Load the wage1 dataset\ndata(\"wage1\")\n\n# Display the first few rows of the dataset\nhead(wage1)##   wage educ exper tenure nonwhite female married numdep smsa northcen south west\n## 1 3.10   11     2      0        0      1       0      2    1        0     0    1\n## 2 3.24   12    22      2        0      1       1      3    1        0     0    1\n## 3 3.00   11     2      0        0      0       0      2    0        0     0    1\n## 4 6.00    8    44     28        0      0       1      0    1        0     0    1\n## 5 5.30   12     7      2        0      0       1      1    0        0     0    1\n## 6 8.75   16     9      8        0      0       1      0    1        0     0    1\n##   construc ndurman trcommpu trade services profserv profocc clerocc servocc    lwage\n## 1        0       0        0     0        0        0       0       0       0 1.131402\n## 2        0       0        0     0        1        0       0       0       1 1.175573\n## 3        0       0        0     1        0        0       0       0       0 1.098612\n## 4        0       0        0     0        0        0       0       1       0 1.791759\n## 5        0       0        0     0        0        0       0       0       0 1.667707\n## 6        0       0        0     0        0        1       1       0       0 2.169054\n##   expersq tenursq\n## 1       4       0\n## 2     484       4\n## 3       4       0\n## 4    1936     784\n## 5      49       4\n## 6      81      64\n# Get a summary of the dataset\nsummary(wage1)##       wage             educ           exper           tenure          nonwhite     \n##  Min.   : 0.530   Min.   : 0.00   Min.   : 1.00   Min.   : 0.000   Min.   :0.0000  \n##  1st Qu.: 3.330   1st Qu.:12.00   1st Qu.: 5.00   1st Qu.: 0.000   1st Qu.:0.0000  \n##  Median : 4.650   Median :12.00   Median :13.50   Median : 2.000   Median :0.0000  \n##  Mean   : 5.896   Mean   :12.56   Mean   :17.02   Mean   : 5.105   Mean   :0.1027  \n##  3rd Qu.: 6.880   3rd Qu.:14.00   3rd Qu.:26.00   3rd Qu.: 7.000   3rd Qu.:0.0000  \n##  Max.   :24.980   Max.   :18.00   Max.   :51.00   Max.   :44.000   Max.   :1.0000  \n##      female          married           numdep           smsa           northcen    \n##  Min.   :0.0000   Min.   :0.0000   Min.   :0.000   Min.   :0.0000   Min.   :0.000  \n##  1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:0.0000   1st Qu.:0.000  \n##  Median :0.0000   Median :1.0000   Median :1.000   Median :1.0000   Median :0.000  \n##  Mean   :0.4791   Mean   :0.6084   Mean   :1.044   Mean   :0.7224   Mean   :0.251  \n##  3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:2.000   3rd Qu.:1.0000   3rd Qu.:0.750  \n##  Max.   :1.0000   Max.   :1.0000   Max.   :6.000   Max.   :1.0000   Max.   :1.000  \n##      south             west           construc          ndurman          trcommpu      \n##  Min.   :0.0000   Min.   :0.0000   Min.   :0.00000   Min.   :0.0000   Min.   :0.00000  \n##  1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.00000  \n##  Median :0.0000   Median :0.0000   Median :0.00000   Median :0.0000   Median :0.00000  \n##  Mean   :0.3555   Mean   :0.1692   Mean   :0.04563   Mean   :0.1141   Mean   :0.04373  \n##  3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:0.00000   3rd Qu.:0.0000   3rd Qu.:0.00000  \n##  Max.   :1.0000   Max.   :1.0000   Max.   :1.00000   Max.   :1.0000   Max.   :1.00000  \n##      trade           services         profserv         profocc          clerocc      \n##  Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n##  1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n##  Median :0.0000   Median :0.0000   Median :0.0000   Median :0.0000   Median :0.0000  \n##  Mean   :0.2871   Mean   :0.1008   Mean   :0.2586   Mean   :0.3669   Mean   :0.1673  \n##  3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000  \n##  Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n##     servocc           lwage            expersq          tenursq       \n##  Min.   :0.0000   Min.   :-0.6349   Min.   :   1.0   Min.   :   0.00  \n##  1st Qu.:0.0000   1st Qu.: 1.2030   1st Qu.:  25.0   1st Qu.:   0.00  \n##  Median :0.0000   Median : 1.5369   Median : 182.5   Median :   4.00  \n##  Mean   :0.1407   Mean   : 1.6233   Mean   : 473.4   Mean   :  78.15  \n##  3rd Qu.:0.0000   3rd Qu.: 1.9286   3rd Qu.: 676.0   3rd Qu.:  49.00  \n##  Max.   :1.0000   Max.   : 3.2181   Max.   :2601.0   Max.   :1936.00\n# Get the structure of the dataset\nstr(wage1)## 'data.frame':    526 obs. of  24 variables:\n##  $ wage    : num  3.1 3.24 3 6 5.3 ...\n##  $ educ    : int  11 12 11 8 12 16 18 12 12 17 ...\n##  $ exper   : int  2 22 2 44 7 9 15 5 26 22 ...\n##  $ tenure  : int  0 2 0 28 2 8 7 3 4 21 ...\n##  $ nonwhite: int  0 0 0 0 0 0 0 0 0 0 ...\n##  $ female  : int  1 1 0 0 0 0 0 1 1 0 ...\n##  $ married : int  0 1 0 1 1 1 0 0 0 1 ...\n##  $ numdep  : int  2 3 2 0 1 0 0 0 2 0 ...\n##  $ smsa    : int  1 1 0 1 0 1 1 1 1 1 ...\n##  $ northcen: int  0 0 0 0 0 0 0 0 0 0 ...\n##  $ south   : int  0 0 0 0 0 0 0 0 0 0 ...\n##  $ west    : int  1 1 1 1 1 1 1 1 1 1 ...\n##  $ construc: int  0 0 0 0 0 0 0 0 0 0 ...\n##  $ ndurman : int  0 0 0 0 0 0 0 0 0 0 ...\n##  $ trcommpu: int  0 0 0 0 0 0 0 0 0 0 ...\n##  $ trade   : int  0 0 1 0 0 0 1 0 1 0 ...\n##  $ services: int  0 1 0 0 0 0 0 0 0 0 ...\n##  $ profserv: int  0 0 0 0 0 1 0 0 0 0 ...\n##  $ profocc : int  0 0 0 0 0 1 1 1 1 1 ...\n##  $ clerocc : int  0 0 0 1 0 0 0 0 0 0 ...\n##  $ servocc : int  0 1 0 0 0 0 0 0 0 0 ...\n##  $ lwage   : num  1.13 1.18 1.1 1.79 1.67 ...\n##  $ expersq : int  4 484 4 1936 49 81 225 25 676 484 ...\n##  $ tenursq : int  0 4 0 784 4 64 49 9 16 441 ...\n##  - attr(*, \"time.stamp\")= chr \"25 Jun 2011 23:03\""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"getting-help-in-r","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.8 Getting Help in R","text":"several ways get help R:? help(): access documentation specific function, type ? followed function name (e.g., ?mean). can also use help(mean).?? help.search(): search help topics related keyword, use ?? followed keyword (e.g., ??regression). can also use help.search(\"regression\").Online Resources: R community active online. Websites like Stack Overflow (https://stackoverflow.com/questions/tagged/r) great places find answers common R questions.Package Vignettes: Many R packages include vignettes, longer, tutorial-style documents demonstrate use package. can access using browseVignettes() function.Package Websites: packages dedicated websites additional resources, tutorials, articles, examples. can typically found searching package name followed “R package” search engine.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"style-guides-in-r","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.9 Style Guides in R","text":"Coding style guides sets conventions prescribe code formatted written. Following style guide can make code readable, maintainable, consistent.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"the-tidyverse-style-guide","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.9.1 The tidyverse Style Guide","text":"tidyverse style guide, developed Hadley Wickham RStudio team, widely used style guide R. covers various aspects coding style, including:File namesObject namesSyntaxSpacingControl flowCommentsYou can find tidyverse style guide : https://style.tidyverse.org/. Note: try follow guide, incredibly good .","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"quick-examples","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.9.2 Quick Examples","text":"examples tidyverse style guidelines:File Names: Use .R extension R script files .Rmd R Markdown files. File names meaningful use lowercase letters, numbers, underscores (e.g., process_data.R, analysis_report.Rmd).Object Names: Use lowercase underscores separate words (e.g., my_variable, data_frame). descriptive concise.Spacing: Place spaces around operators (e.g., x + y, x+y) commas (e.g., mean(x, na.rm = TRUE), mean(x,na.rm=TRUE)).Indentation: Use two spaces indentation. use tabs.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"other-style-guides","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.9.3 Other Style Guides","text":"tidyverse style guide popular, style guides might encounter choose follow, :Google’s R Style Guide: https://google.github.io/styleguide/Rguide.htmlThe Bioconductor Style Guide: https://contributions.bioconductor.org/Ultimately, important thing consistent style, regardless guide choose follow. style guides agree basic principles writing clear readable code.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"protips-for-r-success","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.10 Protips for R Success","text":"","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"enable-helpful-rstudio-options","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.10.1 Enable Helpful RStudio Options","text":"options can make coding experience pleasant efficient:Highlight R function calls: Go “Tools” > “Global Options” > “Code” > “Display” check “Highlight R function calls.” visually distinguish function names code.Rainbow parentheses: “Display” settings, check “Rainbow parentheses.” color-code matching parentheses, making easier track nested functions.Use dark theme: find staring screen long periods, dark theme can help reduce eye strain. Go “Tools” > “Global Options” > “Appearance” choose dark theme “Editor Theme” options.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"good-coding-practices","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.10.2 Good Coding Practices","text":"Organization: Use clear directory structure projects. Keep data, code, output separate folders.Comments: Explain code using comments (lines starting #). Focus explaining behind code, just .Readability: Use consistent spacing indentation make code easy read. RStudio can help automatically indenting code.Section Headings: Use # create section headings organize R scripts. number # determines level heading (e.g., # top-level heading, ## subheading, etc.).Don’t Overwrite: Avoid overwriting original variables. Create new variables need modify data.Backups: Regularly back work. Save reusable code snippets future use. larger projects, consider using separate R scripts different tasks (e.g., data cleaning, analysis, reporting).Coding Language: Learning code like learning new language. takes time practice. patient .Precision: Approach analysis care attention detail. Avoid rushing, especially tired.","code":""},{"path":"tutorial-1-getting-started-with-r-rstudio-and-rmarkdown.html","id":"solutions-to-common-problems","chapter":"2 Tutorial 1: Getting Started with R, RStudio and RMarkdown","heading":"2.10.3 Solutions to Common Problems","text":"Knitting Issues:\nRestart RStudio try knitting .\nCheck special characters (e.g., Greek letters) might causing problems.\nMake sure PDF file (’re knitting PDF) open another program.\nDelete temporary .md .tex files created knitting process.\nConsider disabling “use tinytex compiling .tex files” “Tools” > “Global Options” > “Sweave” ’re issues TinyTeX.\nRestart RStudio try knitting .Check special characters (e.g., Greek letters) might causing problems.Make sure PDF file (’re knitting PDF) open another program.Delete temporary .md .tex files created knitting process.Consider disabling “use tinytex compiling .tex files” “Tools” > “Global Options” > “Sweave” ’re issues TinyTeX.Error Messages:\nCarefully check function arguments. enter correctly right order?\nPay attention capitalization use quotes.\nencounter naming conflicts (e.g., dplyr::recode() vs. car::recode()), specify package want use (e.g., dplyr::recode()).\nCarefully check function arguments. enter correctly right order?Pay attention capitalization use quotes.encounter naming conflicts (e.g., dplyr::recode() vs. car::recode()), specify package want use (e.g., dplyr::recode()).Model Problems:\nDouble-check ’re using correct variables model.\nReview recoding steps performed. make mistakes might affecting results?\nDouble-check ’re using correct variables model.Review recoding steps performed. make mistakes might affecting results?","code":""},{"path":"lecture-2-introduction-to-causal-inference.html","id":"lecture-2-introduction-to-causal-inference","chapter":"3 Lecture 2: Introduction to Causal Inference","heading":"3 Lecture 2: Introduction to Causal Inference","text":"","code":""},{"path":"lecture-2-introduction-to-causal-inference.html","id":"slides-1","chapter":"3 Lecture 2: Introduction to Causal Inference","heading":"Slides","text":"3 Introduction Causal Inference (link)","code":""},{"path":"lecture-2-introduction-to-causal-inference.html","id":"introduction-1","chapter":"3 Lecture 2: Introduction to Causal Inference","heading":"3.1 Introduction","text":"now dive deeper causal inference counterfactual problem. show randomized trails solve counterfactual problem, also counterfactual problem still problem using observational data.lecture slide displayed full :\nFigure 3.1: Slides 3 Introduction Causal Inference.\n","code":"\nlibrary(tidyverse) # for wrangling data\nlibrary(tidylog) # to know what we are wrangling"},{"path":"lecture-2-introduction-to-causal-inference.html","id":"vignette-2.1","chapter":"3 Lecture 2: Introduction to Causal Inference","heading":"3.2 Vignette 2.1","text":"Usually, know data generation process, , gods. Let’s create world taking treatment (e.g., taking pill) positively affect Y (e.g., health) one unit. Let’s run experiment.Now can create counterfactual:Let’s look counterfactual:Now let’s give individual treatment (either pill placebo):can see average effect pill treated group (remember lecture effect , essence, difference receive treatment, ):can plot :","code":"\ndf <- data.frame(health_no_pill= rnorm(5000),\n                 # Randomly assign a treatment\n                 pill=sample(c(0,1),5000,replace=T))\nhist(df$health_no_pill)\nknitr::kable(table(df$pill), format=\"markdown\")\ndf <- df %>%\n  mutate(health_w_pill = health_no_pill + 1) # Our Y when A=1 aka our counterfactual## mutate: new variable 'health_w_pill' (double) with 5,000 unique values and 0% NA\nhealth_w_pill <- cbind.data.frame(df$health_w_pill,\"with Pill\")\ncolnames(health_w_pill) <- c(\"health\",\"treatment\")\nhealth_no_pill <- cbind.data.frame(df$health_no_pill,\"without Pill\")\ncolnames(health_no_pill) <- c(\"health\",\"treatment\")\ncomparison_y <- rbind.data.frame(health_w_pill,health_no_pill)\n\ncomparison_y %>%\n  group_by(treatment) %>%\n  mutate(mean_health = mean(health)) %>%\n  ungroup() %>%\n  ggplot(aes(x=health,fill = treatment,color = treatment)) +\n  geom_density(alpha = .5) +\n  scale_x_continuous(breaks = scales::pretty_breaks(n = 8)) +\n  geom_vline(aes(xintercept = mean_health, color = treatment ),\n             linetype = \"dashed\")## group_by: one grouping variable (treatment)\n## mutate (grouped): new variable 'mean_health' (double) with 2 unique values and 0% NA\n## ungroup: no grouping variables remain\ndf <- df %>%\n  mutate(health_obs = ifelse(pill==1,health_w_pill,health_no_pill))## mutate: new variable 'health_obs' (double) with 5,000 unique values and 0% NA\nhead(df,10)##    health_no_pill pill health_w_pill   health_obs\n## 1     0.622334968    0     1.6223350  0.622334968\n## 2     0.813248502    1     1.8132485  1.813248502\n## 3    -0.880896410    1     0.1191036  0.119103590\n## 4     0.608521707    1     1.6085217  1.608521707\n## 5    -0.874508489    1     0.1254915  0.125491511\n## 6    -0.133693592    1     0.8663064  0.866306408\n## 7     0.576866778    0     1.5768668  0.576866778\n## 8    -0.336585512    1     0.6634145  0.663414488\n## 9    -0.663059981    1     0.3369400  0.336940019\n## 10   -0.001480942    0     0.9985191 -0.001480942\ndf %>%\n  group_by(pill) %>%\n  summarize(health = mean(health_obs))## group_by: one grouping variable (pill)\n## summarize: now 2 rows and 2 columns, ungrouped## # A tibble: 2 × 2\n##    pill  health\n##   <dbl>   <dbl>\n## 1     0 -0.0260\n## 2     1  0.983\ndf %>%\n  group_by(pill) %>%\n  mutate(mean_health_obs = mean(health_obs)) %>%\n  ungroup() %>%\n  ggplot(aes(x=health_obs,fill = factor(pill),color = factor(pill))) +\n  geom_density(alpha = .5) +\n  scale_x_continuous(breaks = scales::pretty_breaks(n = 8)) +\n  geom_vline(aes(xintercept = mean_health_obs, color = factor(pill) ),\n             linetype = \"dashed\")## group_by: one grouping variable (pill)\n## mutate (grouped): new variable 'mean_health_obs' (double) with 2 unique values and 0% NA\n## ungroup: no grouping variables remain"},{"path":"lecture-2-introduction-to-causal-inference.html","id":"vignette-2.2","chapter":"3 Lecture 2: Introduction to Causal Inference","heading":"3.3 Vignette 2.2","text":"Ok… happens randomize? observational data, …Let’s see happens now estimated mean average ‘effect’ (remember lecture effect , essence, difference receive treatment, ):Oh ! actual effect pill, know 1 since created . However, properly model (RDD!), (remember lecture effect , essence, difference receive treatment, ):","code":"\ndf <- data.frame(income = runif(10000)) %>%\n  # In this case, your health is determined randomly AND by your levels of income\n  mutate(health_no_pill = rnorm(10000) + income,\n         health_w_pill = health_no_pill + 1) %>%\n  # Now we give the pill only to people that have money\n  mutate(pill = income > .7,\n         health_obs = ifelse(pill==1,health_w_pill,health_no_pill))## mutate: new variable 'health_no_pill' (double) with 10,000 unique values and 0% NA\n##         new variable 'health_w_pill' (double) with 10,000 unique values and 0% NA\n## mutate: new variable 'pill' (logical) with 2 unique values and 0% NA\n##         new variable 'health_obs' (double) with 10,000 unique values and 0% NA\nhead(df,10)##       income health_no_pill health_w_pill  pill health_obs\n## 1  0.2151152      0.8755887    1.87558866 FALSE  0.8755887\n## 2  0.4458977     -0.9111572    0.08884279 FALSE -0.9111572\n## 3  0.1818968     -0.1259687    0.87403132 FALSE -0.1259687\n## 4  0.4951485      1.4543206    2.45432061 FALSE  1.4543206\n## 5  0.9511732      0.5008189    1.50081889  TRUE  1.5008189\n## 6  0.1181236      0.9807987    1.98079869 FALSE  0.9807987\n## 7  0.9529751      1.5061692    2.50616922  TRUE  2.5061692\n## 8  0.3043475      0.2084923    1.20849231 FALSE  0.2084923\n## 9  0.9377111      1.6119236    2.61192358  TRUE  2.6119236\n## 10 0.6928597      2.0824632    3.08246320 FALSE  2.0824632\ndf %>%\n  group_by(pill) %>%\n  summarize(health = mean(health_obs))## group_by: one grouping variable (pill)\n## summarize: now 2 rows and 2 columns, ungrouped## # A tibble: 2 × 2\n##   pill  health\n##   <lgl>  <dbl>\n## 1 FALSE  0.353\n## 2 TRUE   1.88\ndf %>%\n  filter(abs(income-.7)<.01) %>%\n  group_by(pill) %>%\n  summarize(health = mean(health_obs)) ## BOOM!!## filter: removed 9,796 rows (98%), 204 rows remaining\n## group_by: one grouping variable (pill)\n## summarize: now 2 rows and 2 columns, ungrouped## # A tibble: 2 × 2\n##   pill  health\n##   <lgl>  <dbl>\n## 1 FALSE  0.781\n## 2 TRUE   1.72"},{"path":"tutorial-2-key-concepts.html","id":"tutorial-2-key-concepts","chapter":"4 Tutorial 2: Key Concepts","heading":"4 Tutorial 2: Key Concepts","text":"","code":""},{"path":"tutorial-2-key-concepts.html","id":"what-is-this-tutorial-about","chapter":"4 Tutorial 2: Key Concepts","heading":"What is this tutorial about?","text":"can access tutorial clicking . tutorial quiz key concepts Chapter 1 “Causal Inference: ” Hernán Robins well Chapter 3 (“Describing Variables”) “Effect” Huntington-Klein.","code":""},{"path":"lecture-2-exercises.html","id":"lecture-2-exercises","chapter":"5 Lecture 2 Exercises","heading":"5 Lecture 2 Exercises","text":"tutorial created John Santos (minor adaptations ).","code":""},{"path":"lecture-2-exercises.html","id":"main-exercise","chapter":"5 Lecture 2 Exercises","heading":"5.1 Main Exercise","text":"data ’fertil2’ collected women living Republic Botswana 1988. variable children refers number living children. variable electric binary indicator equal one woman’s home electricity, zero . Using “fertil2” data {wooldridge}…Find smallest largest values children sample. average children?percentage women electricity home?Compute average children without electricity electricity.part (iii), can infer electricity “causes” women fewer children?() Find smallest largest values children sample. average children?Using Base R…Using describe() function psych package…(ii) percentage women electricity home?Using Base…Using tidyverse conventions…14% women electricity.(iii) Compute average children without electricity electricity.Using Base manually calculate averages subsets…code , translated plain English, something like: “Calculate mean fertil2$children cases fertil2$electric equals 0, removing cases NAs.”code calculates compliment code . plain English, code says, “Calculate mean fertil2$children cases fertil2$electric equals 1, removing cases NAs.”Mean number children among women without electricity = 2.33.Mean number children among women electricity = 1.90.also use t.test() command Base R:Mean difference = 0.43, \\(p\\leq0.001\\), 95% CI = 0.27 0.59.average, women electricity 0.43 fewer children women without electricity, difference statistically significant.(iv) part (iii), can infer electricity “causes” women fewer children?women electricity, average, fewer children women without electricity, relationship statistically significant, necessarily infer electricity “causes” women fewer children. need mechanism link electricity children conclude electricity cause.Perhaps, electricity spurious common cause SES.","code":"\nlibrary(wooldridge)\nlibrary(tidyverse)\nlibrary(psych)\ndata(\"fertil2\")\nmin(fertil2$children)## [1] 0\nmax(fertil2$children)## [1] 13\nmean(fertil2$children)## [1] 2.267828\nsummary(fertil2$children)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   0.000   0.000   2.000   2.268   4.000  13.000\ndescribe(fertil2$children)##    vars    n mean   sd median trimmed  mad min max range skew kurtosis   se\n## X1    1 4361 2.27 2.22      2    1.95 2.97   0  13    13 1.07     0.75 0.03\nprop.table(table(fertil2$electric))## \n##         0         1 \n## 0.8597981 0.1402019\nfertil2%>%\n  select(electric)%>%\n  table()/nrow(fertil2)## select: dropped 26 variables (mnthborn, yearborn, age, radio, tv, …)## electric\n##         0         1 \n## 0.8592066 0.1401055\nmean(fertil2$children[fertil2$electric==0], na.rm = TRUE)## [1] 2.327729\nmean(fertil2$children[fertil2$electric==1], na.rm = TRUE)## [1] 1.898527\nt.test(fertil2$children ~ fertil2$electric)## \n##  Welch Two Sample t-test\n## \n## data:  fertil2$children by fertil2$electric\n## t = 5.2409, df = 958, p-value = 1.965e-07\n## alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n## 95 percent confidence interval:\n##  0.2684895 0.5899142\n## sample estimates:\n## mean in group 0 mean in group 1 \n##        2.327729        1.898527\n# dplyr\nlibrary(dplyr)\nfertil2 %>%\n  group_by(electric) %>%\n  summarise(mean = mean(children),\n            sd = sd(children))## group_by: one grouping variable (electric)\n## summarise: now 3 rows and 3 columns, ungrouped## # A tibble: 3 × 3\n##   electric  mean    sd\n##      <int> <dbl> <dbl>\n## 1        0  2.33  2.28\n## 2        1  1.90  1.80\n## 3       NA  2.67  2.89"},{"path":"lecture-2-exercises.html","id":"additional-exercises","chapter":"5 Lecture 2 Exercises","heading":"5.2 Additional Exercises:","text":"Use {ces.Rda} data found .Overall ratings TrudeauThe variables feel_trudeau feeling thermometer ratings Liberal Leader Justin Trudeau. average, Canadians rate ? ’s lowest rating? ’s highest rating?Trudeau ratings groupsDo Trudeau’s ratings vary across groups population? Specifically, look gender (gender), age (agegrp), education (educ).variable (leftrightgrp) measures whether individual places left (0-4), centre (5), right (6-10) political spectrum. ratings Trudeau vary across self-placed ideological categories?","code":""},{"path":"lecture-2-exercises.html","id":"stop","chapter":"5 Lecture 2 Exercises","heading":"5.2.1 STOP!!","text":"continue, try solving exercises . ’s way learn. , come back page see well .","code":""},{"path":"lecture-2-exercises.html","id":"continue","chapter":"5 Lecture 2 Exercises","heading":"5.2.2 Continue","text":"","code":"\nload(\"Sample_data/ces.Rda\")"},{"path":"lecture-2-exercises.html","id":"overall-ratings-of-trudeau","chapter":"5 Lecture 2 Exercises","heading":"5.2.3 Overall ratings of Trudeau","text":"variable feel_trudeau feeling thermometer ratings Liberal Leader Justin Trudeau. average, Canadians rate ? ’s lowest rating? ’s highest rating?Using base R.D’oh! didn’t work NAs.Let’s remove using option na.rm = TRUE.Alternatively, can use summary() command.can using dplyr. can use method calculate summary statistics time.also calculate statistics…","code":"\nmean(ces$feel_trudeau)## [1] NA\nmin(ces$feel_trudeau)## [1] NA\nmax(ces$feel_trudeau)## [1] NA\nmean(ces$feel_trudeau, na.rm = TRUE)## [1] 44.84804\nmin(ces$feel_trudeau, na.rm = TRUE)## [1] 0\nmax(ces$feel_trudeau, na.rm = TRUE)## [1] 100\nsummary(ces$feel_trudeau)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##    0.00    7.00   50.00   44.85   75.00  100.00    2409\nlibrary(dplyr)\nces %>%\n  summarise(mean = mean(feel_trudeau, na.rm = TRUE),\n            min = min(feel_trudeau, na.rm = TRUE),\n            max = max(feel_trudeau, na.rm = TRUE))## summarise: now one row and 3 columns, ungrouped##       mean min max\n## 1 44.84804   0 100\nces %>%\n  summarise(mean = mean(feel_trudeau, na.rm = TRUE),\n            median = median(feel_trudeau, na.rm = TRUE),\n            min = min(feel_trudeau, na.rm = TRUE),\n            max = max(feel_trudeau, na.rm = TRUE),\n            sd = sd(feel_trudeau, na.rm = TRUE),\n            se = sd(feel_trudeau, na.rm = TRUE) / sqrt(sum(!is.na(feel_trudeau))),\n            lower95 = mean - (1.96*se),\n            upper95 = mean + (1.96*se)) ## summarise: now one row and 8 columns, ungrouped##       mean median min max       sd        se  lower95 upper95\n## 1 44.84804     50   0 100 34.54668 0.1838109 44.48777 45.2083"},{"path":"lecture-2-exercises.html","id":"trudeau-ratings-by-groups","chapter":"5 Lecture 2 Exercises","heading":"5.2.4 Trudeau ratings by groups","text":"Trudeau’s ratings vary across groups population? look gender (gender), age (agegrp), education (educ). variable (leftrightgrp) measures whether individual places left (0-4), centre (5), right (6-10) political spectrum. ratings Trudeau vary across self-placed ideological categories?","code":""},{"path":"lecture-2-exercises.html","id":"gender","chapter":"5 Lecture 2 Exercises","heading":"5.2.5 Gender","text":"Using dplyr…can also use base R command t.test().option somewhat limited works comparing across two categories. However, test significance difference, useful.","code":"\nmean(ces$feel_trudeau[ces$gender==\"Man\"], na.rm=T)## [1] 43.35218\nmean(ces$feel_trudeau[ces$gender==\"Woman\"], na.rm=T)## [1] 45.93724\nt.test(ces$feel_trudeau ~ ces$gender)## \n##  Welch Two Sample t-test\n## \n## data:  ces$feel_trudeau by ces$gender\n## t = -6.9009, df = 31483, p-value = 5.266e-12\n## alternative hypothesis: true difference in means between group Man and group Woman is not equal to 0\n## 95 percent confidence interval:\n##  -3.319280 -1.850828\n## sample estimates:\n##   mean in group Man mean in group Woman \n##            43.35218            45.93724\nces %>%\n  group_by(gender) %>%\n  summarise(avg = mean(feel_trudeau, na.rm = TRUE))## group_by: one grouping variable (gender)\n## summarise: now 3 rows and 2 columns, ungrouped## # A tibble: 3 × 2\n##   gender   avg\n##   <fct>  <dbl>\n## 1 Man     43.4\n## 2 Woman   45.9\n## 3 <NA>    44.8\nt.test(ces$feel_trudeau ~ ces$gender, na.rm = TRUE)## \n##  Welch Two Sample t-test\n## \n## data:  ces$feel_trudeau by ces$gender\n## t = -6.9009, df = 31483, p-value = 5.266e-12\n## alternative hypothesis: true difference in means between group Man and group Woman is not equal to 0\n## 95 percent confidence interval:\n##  -3.319280 -1.850828\n## sample estimates:\n##   mean in group Man mean in group Woman \n##            43.35218            45.93724"},{"path":"lecture-2-exercises.html","id":"age","chapter":"5 Lecture 2 Exercises","heading":"5.2.5.1 Age","text":"","code":"\nces %>%\n  group_by(agegrp) %>%\n  summarise(avg = mean(feel_trudeau, na.rm = TRUE))## group_by: one grouping variable (agegrp)\n## summarise: now 3 rows and 2 columns, ungrouped## # A tibble: 3 × 2\n##   agegrp   avg\n##   <fct>  <dbl>\n## 1 18-34   49.1\n## 2 35-54   43.2\n## 3 55+     43.7"},{"path":"lecture-2-exercises.html","id":"education","chapter":"5 Lecture 2 Exercises","heading":"5.2.5.2 Education","text":"","code":"\nces %>%\n  group_by(educ) %>%\n  summarise(avg = mean(feel_trudeau, na.rm = TRUE))## group_by: one grouping variable (educ)\n## summarise: now 5 rows and 2 columns, ungrouped## # A tibble: 5 × 2\n##   educ         avg\n##   <fct>      <dbl>\n## 1 HS or less  38.0\n## 2 Some PSE    42.3\n## 3 Bachelors   51.3\n## 4 Postgrad    52.1\n## 5 <NA>        38.1"},{"path":"lecture-2-exercises.html","id":"ideology","chapter":"5 Lecture 2 Exercises","heading":"5.2.5.3 Ideology","text":"","code":"\nces %>%\n  group_by(leftrightgrp) %>%\n  summarise(avg = mean(feel_trudeau, na.rm = TRUE))## group_by: one grouping variable (leftrightgrp)\n## summarise: now 4 rows and 2 columns, ungrouped## # A tibble: 4 × 2\n##   leftrightgrp   avg\n##   <fct>        <dbl>\n## 1 Left          59.4\n## 2 Centre        42.9\n## 3 Right         37.8\n## 4 <NA>          43.6"},{"path":"lecture-3-core-concepts-of-experimental-design.html","id":"lecture-3-core-concepts-of-experimental-design","chapter":"6 Lecture 3: Core Concepts of Experimental Design","heading":"6 Lecture 3: Core Concepts of Experimental Design","text":"","code":""},{"path":"lecture-3-core-concepts-of-experimental-design.html","id":"slides-2","chapter":"6 Lecture 3: Core Concepts of Experimental Design","heading":"Slides","text":"4 Core Concepts Experimental Design (link)","code":""},{"path":"lecture-3-core-concepts-of-experimental-design.html","id":"introduction-2","chapter":"6 Lecture 3: Core Concepts of Experimental Design","heading":"6.1 Introduction","text":"lecture look (slightly) technical understanding selection bias (understand problem observational data) potential outcomes approach (understand random assignment solves problem).lecture slide displayed full :\nFigure 6.1: Slides 4 Core Concepts Experimental Design.\n","code":""},{"path":"lecture-3-core-concepts-of-experimental-design.html","id":"vignette-3.1","chapter":"6 Lecture 3: Core Concepts of Experimental Design","heading":"6.2 Vignette 3.1","text":"Liebman, Jeffrey B., Erzo FP Luttmer. “people behave differently better understood social security? Evidence field experiment.” American Economic Journal: Economic Policy 7.1 (2015): 275-99.variable interest (DV, Y) paid_work_yes: whether person worked . treatment variable treat: whether got pamphlet . experiment, can compare averages treatment group control group estimate causal effect.effect reported authors!! can also estimate differences gender (?):Treatment effect women… ?averages look great can sure effects mere coincidence product randomization? Let’s add confidence intervals:now gender:Cool…","code":"\nlibrary(tidyverse) # for wrangling data\nlibrary(tidylog) # to know what we are wrangling\nlibrary(sjPlot) # to plot somse models\nlibrary(readstata13) # to load .dta files\nexp_data %>%\n  group_by(treat) %>% \n  summarise(ATE = mean(paid_work_yes, na.rm = T))## group_by: one grouping variable (treat)\n## summarise: now 2 rows and 2 columns, ungrouped## # A tibble: 2 × 2\n##   treat   ATE\n##   <dbl> <dbl>\n## 1     0 0.744\n## 2     1 0.785\nexp_data %>%\n  group_by(female,treat) %>% \n  summarise(ATE = mean(paid_work_yes, na.rm = T))## group_by: 2 grouping variables (female, treat)\n## summarise: now 4 rows and 3 columns, one group variable remaining (female)## # A tibble: 4 × 3\n## # Groups:   female [2]\n##   female treat   ATE\n##    <int> <dbl> <dbl>\n## 1      0     0 0.784\n## 2      0     1 0.787\n## 3      1     0 0.713\n## 4      1     1 0.782\nexp_data$treat <- as.factor(exp_data$treat)\nexp_data$female <- as.factor(exp_data$female)\n\n# Full model\nmodel_1 <- lm(paid_work_yes ~ treat, data = exp_data)\nsummary(model_1)## \n## Call:\n## lm(formula = paid_work_yes ~ treat, data = exp_data)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -0.7845  0.2155  0.2155  0.2555  0.2555 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  0.74446    0.01530  48.666   <2e-16 ***\n## treat1       0.04004    0.02124   1.885   0.0596 .  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.4237 on 1591 degrees of freedom\n##   (890 observations deleted due to missingness)\n## Multiple R-squared:  0.002228,   Adjusted R-squared:  0.001601 \n## F-statistic: 3.553 on 1 and 1591 DF,  p-value: 0.05961\nplot_model(model_1, type = \"pred\", terms = \"treat\") +\n  theme_minimal() +\n  labs(x=\"Treatment\", y=\"Worked +1 Year\",\n       title=\"Predicted Effect of Treatment\")\n# Model by gender\nmodel_2 <- lm(paid_work_yes ~ female + treat + female*treat, data = exp_data)\nsummary(model_2)## \n## Call:\n## lm(formula = paid_work_yes ~ female + treat + female * treat, \n##     data = exp_data)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -0.7871  0.2129  0.2164  0.2176  0.2871 \n## \n## Coefficients:\n##                 Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)     0.783626   0.022885  34.242   <2e-16 ***\n## female1        -0.070685   0.030743  -2.299   0.0216 *  \n## treat1          0.003436   0.031725   0.108   0.9138    \n## female1:treat1  0.066040   0.042680   1.547   0.1220    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.4232 on 1589 degrees of freedom\n##   (890 observations deleted due to missingness)\n## Multiple R-squared:  0.005552,   Adjusted R-squared:  0.003675 \n## F-statistic: 2.957 on 3 and 1589 DF,  p-value: 0.03136\nplot_model(model_2, type = \"int\") +\n  theme_minimal() +\n  labs(x=\"Women\", y=\"Worked +1 Year\", color = \"Treatment\",\n       title=\"Predicted Effect of Treatment by Gender\")"},{"path":"tutorial-3-more-key-concepts.html","id":"tutorial-3-more-key-concepts","chapter":"7 Tutorial 3: More Key Concepts","heading":"7 Tutorial 3: More Key Concepts","text":"","code":""},{"path":"tutorial-3-more-key-concepts.html","id":"what-is-this-tutorial-about-1","chapter":"7 Tutorial 3: More Key Concepts","heading":"What is this tutorial about?","text":"can access tutorial clicking . tutorial test understanding key concepts Chapter 2 “Causal Inference: ” Hernán Robins, focusing randomized experiments. ’ll engage theoretical concepts practical data analysis.","code":""},{"path":"lecture-3-exercises.html","id":"lecture-3-exercises","chapter":"8 Lecture 3 Exercises","heading":"8 Lecture 3 Exercises","text":"tutorial created John Santos (minor adaptations ).start exercises, take look dplyr pipping.","code":""},{"path":"lecture-3-exercises.html","id":"dplyr-primer","chapter":"8 Lecture 3 Exercises","heading":"8.1 {dplyr} primer","text":"dplyr R package part tidyverse family packages. tidyverse provides unified “grammar” coding, opposed idiosyncratic conventions Base R.dplyr focuses data management/transformation.purposes, used dplyr functions include:select(): pick column (.e. variable) multiple columns data frame.mutate(): create new column.summarise(): create new column calculated existing column.group_by(): precedes summarise() command tells R column want summarise.filter(): pick rows (.e. cases) according criterion/criteria.nifty thing dplyr (tidyverse generally) use “pipelines,” created using pipe operator, %>%. means need identify data frame working “pipe ” “pipeline operations”, saves time reduces chance coding errors.(Note: RStudio also “native pipe operator”, |>, works newer versions R yet universally adopted.)","code":""},{"path":"lecture-3-exercises.html","id":"the-select-command-in-action","chapter":"8 Lecture 3 Exercises","heading":"8.1.1 The select() command in action","text":"Say wanted pick feeling thermometer questions sample CES data set.column names:Let’s pull columns using Base R put new data frame called “feelings_base”. ’m feeling lazy, ’m just going parties.also pull columns using index numbers, isn’t recommended index numbers change depending version data set previous operations performed .dplyr way efficient:get even fancier use starts_with() command select every column whose column name starts character string “feel_”:","code":"\nload(\"Sample_data/ces.rda\")\nnames(ces)##  [1] \"weight\"        \"age\"           \"agegrp\"        \"age_18to34\"    \"age_35to54\"   \n##  [6] \"age_55plus\"    \"gender\"        \"woman\"         \"lang\"          \"province\"     \n## [11] \"region\"        \"reg_on\"        \"reg_qc\"        \"reg_atl\"       \"reg_west\"     \n## [16] \"educ\"          \"univ\"          \"relig\"         \"rel_catholic\"  \"rel_christian\"\n## [21] \"rel_other\"     \"rel_none\"      \"income\"        \"incomegrp\"     \"mostimp\"      \n## [26] \"turnout\"       \"leftright\"     \"leftrightgrp\"  \"lr_left\"       \"lr_centre\"    \n## [31] \"lr_right\"      \"feel_lib\"      \"feel_cpc\"      \"feel_ndp\"      \"feel_bloc\"    \n## [36] \"feel_green\"    \"feel_ppc\"      \"feel_trudeau\"  \"feel_scheer\"   \"feel_singh\"   \n## [41] \"feel_blanchet\" \"feel_may\"      \"feel_bernier\"  \"polinterest\"   \"marketlib\"    \n## [46] \"moraltrad\"     \"helpgroups\"\nfeelings_base <- data.frame(\n  feel_lib = ces$feel_lib,\n  feel_cpc = ces$feel_cpc,\n  feel_ndp = ces$feel_ndp,\n  feel_bloc = ces$feel_bloc,\n  feel_green = ces$feel_green,\n  feel_ppc = ces$feel_ppc\n)\nhead(feelings_base)##   feel_lib feel_cpc feel_ndp feel_bloc feel_green feel_ppc\n## 1       52        0       64        NA         97        0\n## 2       51        0       64        40         88        0\n## 3       52       49       NA        NA         NA       NA\n## 4       30       85        0         0          0       30\n## 5       20       62       51        20         50       20\n## 6       81       31       79        NA         85        0\nfeelings_numsel <- ces[32:43]\nhead(feelings_numsel)##   feel_lib feel_cpc feel_ndp feel_bloc feel_green feel_ppc feel_trudeau feel_scheer\n## 1       52        0       64        NA         97        0           55           0\n## 2       51        0       64        40         88        0           53           0\n## 3       52       49       NA        NA         NA       NA           74          24\n## 4       30       85        0         0          0       30            0          80\n## 5       20       62       51        20         50       20           30          60\n## 6       81       31       79        NA         85        0           81          35\n##   feel_singh feel_blanchet feel_may feel_bernier\n## 1         71            15       80            0\n## 2         NA            32       59            0\n## 3         63            NA       56           20\n## 4          0             0        0           10\n## 5         NA            50       60           30\n## 6         70            NA       74            3\nlibrary(dplyr)\nfeelings_dplyr <- select(ces, c(feel_lib:feel_blanchet))## select: dropped 37 variables (weight, age, agegrp, age_18to34, age_35to54, …)\nhead(feelings_dplyr)##   feel_lib feel_cpc feel_ndp feel_bloc feel_green feel_ppc feel_trudeau feel_scheer\n## 1       52        0       64        NA         97        0           55           0\n## 2       51        0       64        40         88        0           53           0\n## 3       52       49       NA        NA         NA       NA           74          24\n## 4       30       85        0         0          0       30            0          80\n## 5       20       62       51        20         50       20           30          60\n## 6       81       31       79        NA         85        0           81          35\n##   feel_singh feel_blanchet\n## 1         71            15\n## 2         NA            32\n## 3         63            NA\n## 4          0             0\n## 5         NA            50\n## 6         70            NA\nfeelings_dplyr2 <- select(ces, starts_with(\"feel_\"))## select: dropped 35 variables (weight, age, agegrp, age_18to34, age_35to54, …)\nhead(feelings_dplyr2)##   feel_lib feel_cpc feel_ndp feel_bloc feel_green feel_ppc feel_trudeau feel_scheer\n## 1       52        0       64        NA         97        0           55           0\n## 2       51        0       64        40         88        0           53           0\n## 3       52       49       NA        NA         NA       NA           74          24\n## 4       30       85        0         0          0       30            0          80\n## 5       20       62       51        20         50       20           30          60\n## 6       81       31       79        NA         85        0           81          35\n##   feel_singh feel_blanchet feel_may feel_bernier\n## 1         71            15       80            0\n## 2         NA            32       59            0\n## 3         63            NA       56           20\n## 4          0             0        0           10\n## 5         NA            50       60           30\n## 6         70            NA       74            3"},{"path":"lecture-3-exercises.html","id":"using-summarise-to-calculate-summary-statistics","chapter":"8 Lecture 3 Exercises","heading":"8.1.2 Using {summarise} to calculate summary statistics","text":"Let’s say want calculate sample mean feeling thermometer score. Base, might something like following, separate line code calculation. (, ’m lazy, ’ve done three, 12 lines total.)dplyr way efficient, thanks %>% operator, allows us write name data frame “pipe ” entire chain commands.","code":"\nmean(ces$feel_lib, na.rm = TRUE)## [1] 48.34366\nmean(ces$feel_cpc, na.rm = TRUE)## [1] 43.61424\nmean(ces$feel_ndp, na.rm = TRUE)## [1] 50.03684\nces %>%\n  select(starts_with(\"feel_\")) %>%\n  summarise(across(everything(), \n                   list(mean), \n                   na.rm = TRUE))## select: dropped 35 variables (weight, age, agegrp, age_18to34, age_35to54, …)\n## summarise: now one row and 12 columns, ungrouped##   feel_lib_1 feel_cpc_1 feel_ndp_1 feel_bloc_1 feel_green_1 feel_ppc_1 feel_trudeau_1\n## 1   48.34366   43.61424   50.03684    23.33321     47.45785   25.81046       44.84804\n##   feel_scheer_1 feel_singh_1 feel_blanchet_1 feel_may_1 feel_bernier_1\n## 1      39.51979     50.36898        27.79471   46.85782       26.14414"},{"path":"lecture-3-exercises.html","id":"the-group_by-and-summarise-combo","chapter":"8 Lecture 3 Exercises","heading":"8.1.3 The {group_by} and {summarise} combo","text":"Calculating group-wise summary statistics Base bit clunky. Recall last week, Base R uses square brackets selection subsetting. want calculate average rating PPC among Western Canadians versus everyone else, something like :dplyr way :first, might think dplyr way longer three instead two lines code. However, efficient less duplication code.dplyr really starts show advantage performan many calculations (variables, groupings, /summary statistics).want calculate dispersion distributions (SD) uncertainty associated estimated means (SE), looks like Base R:dplyr way:","code":"\nmean(ces$feel_ppc[ces$reg_west==1], na.rm = TRUE)## [1] 27.04223\nmean(ces$feel_ppc[ces$reg_west==0], na.rm = TRUE)## [1] 25.25404\nces %>%\n  group_by(reg_west) %>% \n  summarise(mean_ppc = mean(feel_ppc, na.rm = TRUE))## group_by: one grouping variable (reg_west)\n## summarise: now 2 rows and 2 columns, ungrouped## # A tibble: 2 × 2\n##   reg_west mean_ppc\n##      <dbl>    <dbl>\n## 1        0     25.3\n## 2        1     27.0\nsd(ces$feel_ppc[ces$reg_west==1], na.rm = TRUE)## [1] 26.75502\nsd(ces$feel_ppc[ces$reg_west==0], na.rm = TRUE)## [1] 26.43218\nsd(ces$feel_ppc[ces$reg_west==1], na.rm = TRUE) / \n  sqrt(sum(!is.na(ces$feel_ppc[ces$reg_west==1])))## [1] 0.2654482\nsd(ces$feel_ppc[ces$reg_west==0], na.rm = TRUE) / \n  sqrt(sum(!is.na(ces$feel_ppc[ces$reg_west==0])))## [1] 0.1762576\nces %>%\n  group_by(reg_west) %>% \n  summarise(mean_ppc = mean(feel_ppc, na.rm = TRUE),\n            sd_ppc = sd(feel_ppc, na.rm = TRUE),\n            n_ppc = sum(!is.na(feel_ppc)),\n            semean_ppc = sd_ppc / sqrt(n_ppc)\n            )## group_by: one grouping variable (reg_west)\n## summarise: now 2 rows and 5 columns, ungrouped## # A tibble: 2 × 5\n##   reg_west mean_ppc sd_ppc n_ppc semean_ppc\n##      <dbl>    <dbl>  <dbl> <int>      <dbl>\n## 1        0     25.3   26.4 22489      0.176\n## 2        1     27.0   26.8 10159      0.265"},{"path":"lecture-3-exercises.html","id":"lecture-3-exercises-1","chapter":"8 Lecture 3 Exercises","heading":"8.2 Lecture 3 Exercises","text":"Using ’fertil2’ dataset ’wooldridge’ women living Republic Botswana 1988,() Calculate means mean differences without electricity following two characteristics:education (educ)age first child born (agefbrth)’ll start loading dataset.loading dataset, let’s look summary statistics (also known descriptive statistics simply descriptives) variables ’re analyze. looking , keep mine units analysis whether missing values deal analyze data.Now can calculate summary statistics group two variables.Difference education attainment without (0) (1) electricity.Without (0) = 5.382 yearsWith (1) = 8.763 yearsDifference = 8.763 - 5.382 == 3.381 years schooling(Note: isn’t important now, average among NAs group often indicates missingness bias results. later methods courses, ’ll learn ways test deal .)Difference age first child born without (0) (1) electricity.Without (0) = 18.825 years oldWith (1) = 20.162 years oldDifference = 20.162 - 18.825 == 1.337 years old(ii) Evaluate mean differences statistically significant 0.01 0.05 levels.education, difference means = 3.381 years, p = 2.2*10^-16 (less 0.001), difference significant 0.05 0.01 levels. fact, even significant 0.001 level.Using confidence interval approach, also say 95% confidence interval difference -3.720 -3.041, include zero. indicates difference statistically significant 0.05 level.code uses “formula notation”, quantitative variable listed first, tilde (“~”), categorical variable.use formula notation incorrect order, won’t work, following case: t.test(fertil2$electric ~ fertil2$agefbrth).Specifying “vector notation” specifying two complementary subsets (using square brackets, []) also works. vector notation approach works regardless order specify two vectors, can seen example :Regardless approach use, age birth first child, difference means = 1.337 years (p = 1.432*10^-13). , difference significant 0.05 0.01 levels. fact, even significant 0.001 level.Using confidence interval approach, also say 95% confidence interval difference -1.683 -0.990, include zero. indicates difference statistically significant 0.05 level.note Stata users: default, t.test() uses unequal variances (proposed Welch). possible perform “vanilla” Student’s t-test assumes equal variances specifying option var.equal = TRUE. However, practice, reason . Welch’s t-test robust Student’s t-test assumptions test violated, performs just well (rare) cases assumptions met. compare results R Stata, t-tests usually match Stata, default, assumes equal variances. can get Stata assume unequal variances specifying option (e.g. ttest agefbrth, (electric) unequal welch).(iii) Interpret results.Women access electricity , average, 3.4 years education 1.3 years younger women access electricity. mean differences significant 0.01 0.05 levels.(iv) analysis, say comparisons women without electricity apples--apples apples--oranges?apples--oranges comparisons.(v) affect ability conclude anything relationship access electricity number children?previous exercise, found women access electricity , average, fewer children women access electricity (mean difference = 0.43 children, p<0.001). Women electricity systematically different women without electricity terms children, children later, years schooling. Presumably, children, children, years schooling also related. , sure true link access electricity number children woman without controlling factors.","code":"\nlibrary(wooldridge)\ncupcakes <- get(data('fertil2'))\nhead(cupcakes)##   mnthborn yearborn age electric radio tv bicycle educ ceb agefbrth children knowmeth\n## 1        5       64  24        1     1  1       1   12   0       NA        0        1\n## 2        1       56  32        1     1  1       1   13   3       25        3        1\n## 3        7       58  30        1     0  0       0    5   1       27        1        1\n## 4       11       45  42        1     0  1       0    4   3       17        2        1\n## 5        5       45  43        1     1  1       1   11   2       24        2        1\n## 6        8       52  36        1     0  0       0    7   1       26        1        1\n##   usemeth monthfm yearfm agefm idlnchld heduc agesq urban urb_educ spirit protest\n## 1       0      NA     NA    NA        2    NA   576     1       12      0       0\n## 2       1      11     80    24        3    12  1024     1       13      0       0\n## 3       0       6     83    24        5     7   900     1        5      1       0\n## 4       0       1     61    15        3    11  1764     1        4      0       0\n## 5       1       3     66    20        2    14  1849     1       11      0       1\n## 6       1      11     76    24        4     9  1296     1        7      0       0\n##   catholic frsthalf educ0 evermarr\n## 1        0        1     0        0\n## 2        0        1     0        1\n## 3        0        0     0        1\n## 4        0        0     0        1\n## 5        0        1     0        1\n## 6        0        0     0        1\ndata(\"fertil2\")\nhead(fertil2)##   mnthborn yearborn age electric radio tv bicycle educ ceb agefbrth children knowmeth\n## 1        5       64  24        1     1  1       1   12   0       NA        0        1\n## 2        1       56  32        1     1  1       1   13   3       25        3        1\n## 3        7       58  30        1     0  0       0    5   1       27        1        1\n## 4       11       45  42        1     0  1       0    4   3       17        2        1\n## 5        5       45  43        1     1  1       1   11   2       24        2        1\n## 6        8       52  36        1     0  0       0    7   1       26        1        1\n##   usemeth monthfm yearfm agefm idlnchld heduc agesq urban urb_educ spirit protest\n## 1       0      NA     NA    NA        2    NA   576     1       12      0       0\n## 2       1      11     80    24        3    12  1024     1       13      0       0\n## 3       0       6     83    24        5     7   900     1        5      1       0\n## 4       0       1     61    15        3    11  1764     1        4      0       0\n## 5       1       3     66    20        2    14  1849     1       11      0       1\n## 6       1      11     76    24        4     9  1296     1        7      0       0\n##   catholic frsthalf educ0 evermarr\n## 1        0        1     0        0\n## 2        0        1     0        1\n## 3        0        0     0        1\n## 4        0        0     0        1\n## 5        0        1     0        1\n## 6        0        0     0        1\nsummary(fertil2$electric)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##  0.0000  0.0000  0.0000  0.1402  0.0000  1.0000       3\nsummary(fertil2$educ)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   0.000   3.000   7.000   5.856   8.000  20.000\nsummary(fertil2$agefbrth)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##   10.00   17.00   19.00   19.01   20.00   38.00    1088\nlibrary(dplyr)\nfertil2 %>%\n  group_by(electric) %>%\n  summarise(mean_educ = mean(educ, na.rm = TRUE))## group_by: one grouping variable (electric)\n## summarise: now 3 rows and 2 columns, ungrouped## # A tibble: 3 × 2\n##   electric mean_educ\n##      <int>     <dbl>\n## 1        0      5.38\n## 2        1      8.76\n## 3       NA      5.67\nfertil2 %>%\n  group_by(electric) %>%\n  summarise(mean_agefbrth = mean(agefbrth, na.rm = TRUE))## group_by: one grouping variable (electric)\n## summarise: now 3 rows and 2 columns, ungrouped## # A tibble: 3 × 2\n##   electric mean_agefbrth\n##      <int>         <dbl>\n## 1        0          18.8\n## 2        1          20.2\n## 3       NA          18\nt.test(fertil2$educ ~ fertil2$electric)## \n##  Welch Two Sample t-test\n## \n## data:  fertil2$educ by fertil2$electric\n## t = -19.569, df = 790.18, p-value < 2.2e-16\n## alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n## 95 percent confidence interval:\n##  -3.719608 -3.041416\n## sample estimates:\n## mean in group 0 mean in group 1 \n##        5.382172        8.762684\nt.test(fertil2$agefbrth ~ fertil2$electric)## \n##  Welch Two Sample t-test\n## \n## data:  fertil2$agefbrth by fertil2$electric\n## t = -7.5801, df = 562.66, p-value = 1.432e-13\n## alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n## 95 percent confidence interval:\n##  -1.6827861 -0.9901586\n## sample estimates:\n## mean in group 0 mean in group 1 \n##        18.82545        20.16193\nt.test(fertil2$agefbrth[fertil2$electric==1],fertil2$agefbrth[fertil2$electric==0])## \n##  Welch Two Sample t-test\n## \n## data:  fertil2$agefbrth[fertil2$electric == 1] and fertil2$agefbrth[fertil2$electric == 0]\n## t = 7.5801, df = 562.66, p-value = 1.432e-13\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  0.9901586 1.6827861\n## sample estimates:\n## mean of x mean of y \n##  20.16193  18.82545\nt.test(fertil2$agefbrth[fertil2$electric==0],fertil2$agefbrth[fertil2$electric==1])## \n##  Welch Two Sample t-test\n## \n## data:  fertil2$agefbrth[fertil2$electric == 0] and fertil2$agefbrth[fertil2$electric == 1]\n## t = -7.5801, df = 562.66, p-value = 1.432e-13\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  -1.6827861 -0.9901586\n## sample estimates:\n## mean of x mean of y \n##  18.82545  20.16193\nfertil2 %>%\n  select(c(electric, educ, agefbrth)) %>%\n  filter(!is.na(electric)) %>%\n  group_by(electric) %>%\n  summarise(mean_agefbrth = mean(agefbrth, na.rm = TRUE),\n            mean_educ = mean(educ, na.rm = TRUE)) %>%\n  mutate(electric = factor(electric,\n                           levels = c(0,1),\n                           labels = c(\"No electricity\",\n                                      \"Electricity\")))## select: dropped 24 variables (mnthborn, yearborn, age, radio, tv, …)\n## filter: removed 3 rows (<1%), 4,358 rows remaining\n## group_by: one grouping variable (electric)\n## summarise: now 2 rows and 3 columns, ungrouped\n## mutate: converted 'electric' from integer to factor (0 new NA)## # A tibble: 2 × 3\n##   electric       mean_agefbrth mean_educ\n##   <fct>                  <dbl>     <dbl>\n## 1 No electricity          18.8      5.38\n## 2 Electricity             20.2      8.76"},{"path":"lecture-3-exercises.html","id":"additional-exercises-1","chapter":"8 Lecture 3 Exercises","heading":"8.3 Additional Exercises:","text":"Using ‘ces’ dataset, calculate means mean differences support market liberalism (marketlib) across whether someone lives Western Canada (reg_west) men women (gender);evaluate mean differences statistically significant 0.01 0.05 levels;interpret results way practice exercises lecture;","code":""},{"path":"lecture-3-exercises.html","id":"stop-1","chapter":"8 Lecture 3 Exercises","heading":"8.3.1 STOP!!","text":"continue, try solving exercises . ’s way learn. , come back page see well .","code":""},{"path":"lecture-3-exercises.html","id":"continue-1","chapter":"8 Lecture 3 Exercises","heading":"8.3.2 Continue","text":"’ll start loading dataset taking look univariate summaries variable ’ll analyzing.Market liberalism measured scale 0 16 points, average 8.59.Region West gender binary variables.NAs marketlib gender.","code":"\nload(\"Sample_data/ces.rda\")\nsummary(ces$marketlib)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##    0.00    6.00    9.00    8.59   11.00   16.00   32684\nsummary(ces$reg_west)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##  0.0000  0.0000  0.0000  0.3145  1.0000  1.0000\nsummary(ces$gender)##   Man Woman  NA's \n## 15517 21928   288"},{"path":"lecture-3-exercises.html","id":"group-wise-means-mean-differences-and-statistical-significance","chapter":"8 Lecture 3 Exercises","heading":"8.3.3 Group-wise means, mean differences, and statistical significance","text":"’m going use t.test() get significance testing. dplyr version follows, want see .Among live Western Canada, average market liberalism score 8.748. Among live Western Canada, score 8.498. means , average, living Western Canada 0.25 points 16 supportive market liberalism living elsewhere country. difference significant 0.05 level (p=0.018).Among men, average market liberalism score 9.079. Among women, score 8.156. means , average, men living Western Canada 0.923 points 16 supportive market liberalism women. difference significant 0.001 level (p=<0.001).dplyr version:","code":"\nt.test(ces$marketlib ~ ces$reg_west)## \n##  Welch Two Sample t-test\n## \n## data:  ces$marketlib by ces$reg_west\n## t = -2.3712, df = 3428.5, p-value = 0.01779\n## alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n## 95 percent confidence interval:\n##  -0.4571754 -0.0433279\n## sample estimates:\n## mean in group 0 mean in group 1 \n##        8.498180        8.748431\nt.test(ces$marketlib ~ ces$gender)## \n##  Welch Two Sample t-test\n## \n## data:  ces$marketlib by ces$gender\n## t = 9.4086, df = 5012.2, p-value < 2.2e-16\n## alternative hypothesis: true difference in means between group Man and group Woman is not equal to 0\n## 95 percent confidence interval:\n##  0.7309037 1.1156689\n## sample estimates:\n##   mean in group Man mean in group Woman \n##            9.079404            8.156118\nces %>%\n  group_by(reg_west) %>% \n  summarise(mean_marketlib = mean(marketlib, na.rm = TRUE))## group_by: one grouping variable (reg_west)\n## summarise: now 2 rows and 2 columns, ungrouped## # A tibble: 2 × 2\n##   reg_west mean_marketlib\n##      <dbl>          <dbl>\n## 1        0           8.50\n## 2        1           8.75\nces %>%\n  group_by(gender) %>% \n  summarise(mean_marketlib = mean(marketlib, na.rm = TRUE))## group_by: one grouping variable (gender)\n## summarise: now 3 rows and 2 columns, ungrouped## # A tibble: 3 × 2\n##   gender mean_marketlib\n##   <fct>           <dbl>\n## 1 Man              9.08\n## 2 Woman            8.16\n## 3 <NA>             5.38"},{"path":"lecture-3-exercises.html","id":"interpretation-of-results","chapter":"8 Lecture 3 Exercises","heading":"8.3.4 Interpretation of results","text":"Among sets comparisons statistically significant differences support principle market liberalism. However, gender region, necessarily conclude ’ve solved reason Westerners supportive free market Canadians men supportive free market women. Moreover, region, magnitude difference quarter point 16 scale, dubious substantive significance.variables usually referred demographic characteristics, personal attributes individual. tend “far back” processes lead outcomes interest political science (like policy preferences vote choice) often exert effect intervening variables, things come -personal characteristics outcomes.","code":""}]
